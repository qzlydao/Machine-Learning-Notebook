{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章 统计学习方法概论\n",
    "\n",
    "## 1.1 统计学习\n",
    "\n",
    "### 1.1.1 统计学习的特点\n",
    "\n",
    "#### 统计学习定义\n",
    "\n",
    "统计学习（statistical learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。\n",
    "\n",
    "#### 统计学习特点\n",
    "\n",
    "1. \n",
    "\n",
    "### 1.1.2 统计学习的对象\n",
    "\n",
    "对象是**数据**。\n",
    "\n",
    "关于数据的`基本假设`：同类数据具有一定的统计规律性。\n",
    "\n",
    "\n",
    "### 1.1.3 统计学习的目的\n",
    "\n",
    "用于对数据进行预测与分析。\n",
    "\n",
    "\n",
    "### 1.1.4 统计学习的方法\n",
    "\n",
    "1. 监督学习\n",
    "2. 非监督学习\n",
    "3. 半监督学习\n",
    "4. 强化学习\n",
    "\n",
    "\n",
    "监督学习方法可以概括为：\n",
    "\n",
    "1. 从给定训练数据集合出发，假设数据是`独立同分布`产生的；\n",
    "2. 假设要学习的模型属于某个函数的集合，称为`假设空间（hypothesis space）`；\n",
    "3. 应用某个评价准则，从假设空间中选取一个最优模型；\n",
    "4. 最优模型的选取由算法实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 监督学习\n",
    "\n",
    "### 1.2.1 基本概念\n",
    "\n",
    "#### 输入空间（input space）\n",
    "\n",
    "在监督学习中，输入所有可能取值的集合。\n",
    "\n",
    "\n",
    "\n",
    "#### 输出空间（output space）\n",
    "\n",
    "在监督学习中，输出所有可能取值的集合。\n",
    "\n",
    "输入与输出空间可以是同一个，也可以不是同一个；但一般地，输出空间远远小于输入空间。\n",
    "\n",
    "\n",
    "\n",
    "#### 实例（instance）\n",
    "\n",
    "每一个具体的输入。\n",
    "\n",
    "\n",
    "\n",
    "#### 特征空间（feature space）\n",
    "\n",
    "实例通常由特征向量（feature vector）表示。所有特征向量存在的空间称为特征空间（feature space）。\n",
    "\n",
    "\n",
    "\n",
    "#### 输入空间与特征空间\n",
    "\n",
    "有时假设输入空间与特征空间为相同空间；\n",
    "\n",
    "有时假设输入空间与特征空间为不同的空间，将实例从输入空间==映射==到特征空间。\n",
    "\n",
    "**模型实际上都是定义在特征空间的**。\n",
    "\n",
    "#### 符号定义\n",
    "\n",
    "实例$x$的特征向量记作：\n",
    "$$\n",
    "x=(x^{(1)},x^{(2)},...,x^{(i)},...,x^{(n)})^{T}\n",
    "$$\n",
    "$x^{i}$表示实例$x$的第$i$个特征。\n",
    "\n",
    "第$i$个输入变量记作：\n",
    "$$\n",
    "{ x }_{ i }=\\left( { x }_{ i }^{ \\left( 1 \\right)  },{ x }_{ i }^{ \\left( 2 \\right)  },\\cdots ,{ x }_{ i }^{ \\left( n \\right)  } \\right) ^{ T }\n",
    "$$\n",
    "\n",
    "#### 问题分类\n",
    "\n",
    "1. 回归问题\n",
    "\n",
    "   > 输入变量与输出变量均为连续变量的预测问题成为回归问题。\n",
    "\n",
    "2. 分类问题\n",
    "\n",
    "   > 输出变量为有限个离散变量的预测问题称为分类问题。\n",
    "\n",
    "3. 标注问题\n",
    "\n",
    "   > 输入变量与输出变量均为==变量序列==的预测问题，称为标注问题。\n",
    "\n",
    "### 1.2.2 联合概率分布\n",
    "\n",
    "统计学习假设数据存在一定的统计规律，$X$和$Y$具有联合概率分布$P(X,Y)$的假设是监督学习关于数据的`基本假设`。\n",
    "\n",
    "\n",
    "\n",
    "### 1.2.3 假设空间\n",
    "\n",
    "`模型`是输入空间到输出空间的映射的集合，这个集合就是`假设空间`。\n",
    "\n",
    "监督学习的模型可以是`概率模型`，也可以是`非概率模型`，有条件概率分布$P(Y|X)$或决策函数（decision function）$Y=f(X)$表示。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 统计学习三要素\n",
    "\n",
    "方法 = 模型 + 策略 + 算法\n",
    "\n",
    "### 1.3.1 模型\n",
    "\n",
    "在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。\n",
    "\n",
    "\n",
    "\n",
    "**符号定义**：\n",
    "\n",
    "$\\mathcal{F}$ ：假设空间\n",
    "\n",
    "$\\mathcal{X} $ ：输入空间\n",
    "\n",
    "$\\mathcal{Y} $ ：输出空间\n",
    "\n",
    "$X$ ：输入空间上的变量\n",
    "\n",
    "$Y$ ：输出空间上的变量\n",
    "\n",
    "\n",
    "\n",
    "**假设空间定义为决策函数的集合：**\n",
    "\n",
    "$\\mathcal{F}=\\left\\{ f|Y={ f }_{ \\theta  }\\left( X \\right) ,\\theta \\in { \\pmb{R} }^{ n } \\right\\} $\n",
    "\n",
    "\n",
    "\n",
    "**假设空间也可以定义为条件概率分布族：**\n",
    "\n",
    "$\\mathcal{F}=\\left\\{ P|{ P }_{ \\theta  }\\left( Y|X \\right) ,\\theta \\in { R }^{ n } \\right\\} $\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.2 策略\n",
    "\n",
    "统计学习的**目标**在于从假设空间中选取最优模型。\n",
    "\n",
    "**损失函数**：度量模型一次预测的好坏。\n",
    "\n",
    "**风险函数**：度量平均意义下模型预测的好坏。\n",
    "\n",
    "\n",
    "\n",
    "#### 1.3.2.1 损失函数和风险函数\n",
    "\n",
    "损失函数（loass function）或代价函数（cost function）用来度量预测值$f(x)$与真实值$Y$之间的偏差，一般是非负实值函数，记为$L(Y,f(X))$.\n",
    "\n",
    "\n",
    "\n",
    "**常用损失函数：**\n",
    "\n",
    "1. 0-1 损失函数\n",
    "\n",
    "2. 平方损失函数\n",
    "\n",
    "3. 绝对损失函数\n",
    "\n",
    "4. 对数损失函数或对数似然损失函数\n",
    "\n",
    "   $L(Y,P(Y|X))=-logP(Y|X)$\n",
    "   \n",
    "   \n",
    "**风险函数/期望损失：**\n",
    "\n",
    "<img src='1.3_风险函数.png' style='zoom:50%'/>\n",
    "但是联合概率$P(x,y)$是未知的。\n",
    "\n",
    "\n",
    "\n",
    "**经验风险/经验损失：**\n",
    "<img src='1.3_经验风险.png' style='zoom:50%'/>\n",
    "\n",
    "\n",
    "根据`大数定律`，当样本容量$N$趋于无穷时，经验风险${ R }_{ emp }\\left( f \\right) $趋于期望风险${ R }_{ exp }\\left( f \\right) $\n",
    "\n",
    "\n",
    "\n",
    "#### 1.3.2.2 经验风险最小化与结构风险最小化\n",
    "\n",
    "根据经验风险最小化（empirical risk minimization，ERM）求最优模型对应的优化问题：\n",
    "$$\n",
    "\\min _{ f\\in \\mathcal{F } }{ \\frac { 1 }{ N }  } \\sum _{ i=1 }^{ N }{ L\\left( { y }_{ i },f\\left( { x }_{ i } \\right)  \\right)  }\n",
    "$$\n",
    "**MLE就是经验风险最小化的例子。**\n",
    "\n",
    "**缺点：**当样本 容量很小时，容易`过拟合`。\n",
    "\n",
    "\n",
    "\n",
    "根据结构风险最小化（structural risk minimization，SRM）求最优模型对应的优化问题：\n",
    "$$\n",
    "\\min _{ f\\in \\mathcal{ F } }{ \\frac { 1 }{ N }  } \\sum _{ i=1 }^{ N }{ L\\left( { y }_{ i },f\\left( { x }_{ i } \\right)  \\right)  } +\\lambda J\\left( f \\right)\n",
    "$$\n",
    "$J(f)$为模型的复杂度，模型$f$越复杂，$J(f)$就越大，也就是说复杂度表示了对复杂模型的惩罚。\n",
    "\n",
    "\n",
    "\n",
    "MAP就是SRM的一个例子。\n",
    "\n",
    "### 1.3.3 算法\n",
    "\n",
    "统计学习问题归结为`最优化问题`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 模型评估与模型选择\n",
    "\n",
    "### 1.4.1 训练误差与测试误差\n",
    "\n",
    "通常将学习方法对未知数据的预测能力成为`泛化能力（generalization ability）`.\n",
    "\n",
    "\n",
    "### 1.4.2 过拟合与模型选择\n",
    "\n",
    "如果假设空间含有不同复杂度的模型时，就面临`模型选择（model selection）`的问题。\n",
    "\n",
    "`过拟合（over-fitting）`指学习时选择的模型包含的参数过多，以至于出现对已知数据预测的很好，但对未知数据预测的很差的现象。  \n",
    "\n",
    "训练误差和测试误差与模型复杂度之间的关系图：  \n",
    "<img src=\"1.4_模型评估.png\" alt=\"屏幕快照 2019-12-15 23.34.48\" style=\"zoom:50%;\" />   \n",
    "**两种常用的模型选择方法：**\n",
    "\n",
    "- 正则化\n",
    "\n",
    "- 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1.5 正则化与交叉验证\n",
    "\n",
    "### 1.5.1 正则化\n",
    "\n",
    "正则化项（regularizer）或罚项（penalty term）一般是模型复杂度的==单调递增函数==。\n",
    "\n",
    "\n",
    "\n",
    "**一般形式：**\n",
    "$$\n",
    "\\min _{ f\\in \\mathcal{ F } }{ \\frac { 1 }{ N }  } \\sum _{ i=1 }^{ N }{ L\\left( { y }_{ i },f\\left( { x }_{ i } \\right)  \\right)  } +\\lambda J\\left( f \\right)\n",
    "$$\n",
    "**作用：**`选择经验风险与模型复杂度同时较小的模型`。\n",
    "\n",
    "\n",
    "\n",
    "**正则化符合奥卡姆剃刀原理：** 在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的模型才是最好的模型，也就是应该选择的模型。\n",
    "\n",
    "\n",
    "\n",
    "### 1.5.2 交叉验证\n",
    "\n",
    "如果给定的`样本数据充足`，可以`随机`地将数据分成三部分，分别是训练集，验证机和测试集。\n",
    "\n",
    "但一般地，数据不是充足的，可以采用交叉验证方法：\n",
    "\n",
    "#### 1.5.2.1 简单交叉验证\n",
    "\n",
    "随机将数据分成两部分，比如70%数据作训练集，30%数据作测试集。\n",
    "\n",
    "\n",
    "\n",
    "#### 1.5.2.2 S折交叉验证\n",
    "\n",
    "将数据切分称S个大小相同的子集，利用S-1个子集进行训练，余下的作测试。重复S次，最后选出S次测评中平均测试误差最小的模型。\n",
    "\n",
    "\n",
    "\n",
    "#### 1.5.2.3 留一交叉验证\n",
    "\n",
    "S折交叉验证的特殊情况，S=N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1.6 泛化能力\n",
    "\n",
    "\n",
    "\n",
    "## 1.7 生成模型与判别模型\n",
    "\n",
    "[深入浅出最大熵模型](https://www.cnblogs.com/rossiXYZ/p/12244760.html)\n",
    "\n",
    "监督学习学得的模型一般形式为决策函数：\n",
    "$$\n",
    "Y=f(X)\n",
    "$$\n",
    "或者条件概率分布：\n",
    "$$\n",
    "P(Y|X)\n",
    "$$\n",
    "监督学习方法可分为`生成方法（generativa approach）`或`判别方法（discriminative approach）`.所需模型对应称为`生成模型`和`判别模型`。\n",
    "\n",
    "\n",
    "\n",
    "### 1.7.1 生成模型\n",
    "\n",
    "生成方法由数据学得联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测模型，即生成模型：\n",
    "$$\n",
    "P\\left( Y|X \\right) =\\frac { P\\left( X,Y \\right)  }{ P\\left( X \\right)  } \n",
    "$$\n",
    "**典型的生成模型：**\n",
    "\n",
    "1. 朴素贝叶斯法；\n",
    "2. 隐马尔科夫模型\n",
    "\n",
    "\n",
    "\n",
    "**生成模型的特点：**\n",
    "\n",
    "1. 可以还原出联合概率分布$P(X,Y)$；\n",
    "2. 学习收敛速度更快，当样本容量增加时，模型可以更快地收敛于真实模型；\n",
    "3. 当存在隐变量时，仍可以用生成方法，但判别方法就不能再用。\n",
    "\n",
    "\n",
    "\n",
    "### 1.7.2 判别模型\n",
    "\n",
    "判别方法由数据直接学习决策函数$f(X)$或条件概率分布$P(Y|X)$作为预测的模型，即`判别模型`。\n",
    "\n",
    "\n",
    "\n",
    "**典型的判别模型：**\n",
    "\n",
    "1. $k$近临法；\n",
    "2. 感知机；\n",
    "3. 决策树；\n",
    "4. Logistic Regression；\n",
    "5. 最大熵模型；\n",
    "6. SVM；\n",
    "7. AdaBoost;\n",
    "8. 条件随机场\n",
    "\n",
    "\n",
    "\n",
    "**判别模型的特点：**\n",
    "\n",
    "1. 直接面对预测，往往准确率更高；\n",
    "2. 由于直接学习$P(Y|X)$或$f(X)$，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。\n",
    "\n",
    "\n",
    "\n",
    "## 1.8 分类问题\n",
    "\n",
    "对于二分类问题，常用的评价指标是`精确率（precision）`和`召回率（recall）`.\n",
    "\n",
    "对分类结果的4种情况分别记作：\n",
    "\n",
    "$TP$——将正类预测为正类数；\n",
    "\n",
    "$FN$——将正类预测为负类数；\n",
    "\n",
    "$FP$——将负类预测为正类数；\n",
    "\n",
    "$TN$——将负类预测为负类数。\n",
    "\n",
    "\n",
    "\n",
    "**精确率定义：**\n",
    "$$\n",
    "P=\\frac { TP }{ TP+FP } \n",
    "$$\n",
    "即：预测为正的数据中，真的为正的比例。\n",
    "\n",
    "\n",
    "\n",
    "**召回率定义：**\n",
    "$$\n",
    "R=\\frac { TP }{ TP+FN } \n",
    "$$\n",
    "即：对于所有正数据，有多少比例是预测准了的。\n",
    "\n",
    "\n",
    "\n",
    "一般地，精确率和召回率不可能都高，更常用的是它们的调和均值${ F }_{ 1 }$:\n",
    "$$\n",
    "\\frac { 2 }{ { F }_{ 1 } } =\\frac { 1 }{ P } +\\frac { 1 }{ F }\n",
    "$$\n",
    "\n",
    "$$\n",
    "{ F }_{ 1 }=\\frac { 2TP }{ 2TP+FP+FN } \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.9 标注问题\n",
    "\n",
    "\n",
    "\n",
    "## 1.10 回归问题\n",
    "\n",
    "回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系。\n",
    "\n",
    "回归问题的学习等价于`函数拟合`：选择一条函数曲线使其很好地拟合已知数据且能很好地预测未知数据。\n",
    "\n",
    "\n",
    "\n",
    "**分类问题分类：**\n",
    "\n",
    "1. 按照输入变量的个数，分为`一元回归`和`多元回归`；\n",
    "2. 按照输入和输出变量之间的关系，分为`线性回归`和`非线性回归`。\n",
    "\n",
    "\n",
    "\n",
    "## 1.11 课后习题\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.12 拓展问题\n",
    "\n",
    "#### 1. P5 监督模型可以是概率模型或非概率模型，怎么理解LR？\n",
    "\n",
    "\n",
    "\n",
    "#### 2. P9 极大似然估计就是经验风险最小化的例子，怎么理解？\n",
    "\n",
    "\n",
    "\n",
    "#### 3. P9 MAP就是结构风险最小化的例子，怎么理解？\n",
    "\n",
    "\n",
    "\n",
    "#### 4. P14 从贝叶斯估计角度，正则化项对应于模型的先验概率...，怎么理解？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
