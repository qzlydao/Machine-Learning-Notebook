{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 单词文本矩阵（word-document matrix）$X$  \n",
    "\n",
    "- 单词话题矩阵（word-topic matrix）$T$  \n",
    "\n",
    "- 话题文本矩阵（topic-document matrix）$Y$\n",
    "\n",
    "<font color=red>$X \\approx TY$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第17章 潜在语义分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 潜在语义分析（Latent Semantic Analysis,LSA）是一种无监督学习，主要用于<font color=blue>文本的话题分析</font>，其特点是<font color=red>通过矩阵分解，发现文本与单词之间的基于话题的语义关系</font>。  \n",
    "\n",
    "\n",
    "2. 话题分析（topic modeling）试图从大量的文本数据中发现潜在的话题，以<font color=blue>话题向量</font>表示文本的语义内容，以话题向量空间的度量更准确地表示文本之间的语义相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.1 单词向量空间与话题向量空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.1 单词向量空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本集合$D=\\left\\{d_{1}, d_{2}, \\cdots, d_{n}\\right\\}$，表示$n$个文本；  \n",
    "\n",
    "单词集合$W=\\left\\{w_{1}, w_{2}, \\cdots, w_{m}\\right\\}$，表示所有文本中出现的$m$个单词。 \n",
    "\n",
    "将单词在文本中出现的数据用一个单词-文本矩阵（word-document matrix）表示，记作$X$  \n",
    "\n",
    "$$\n",
    "X = \\left[ \\begin{array} { c c c c } x _ { 11 } & x _ { 12 } & \\cdots & x _ { 1 n } \\\\ x _ { 21 } & x _ { 22 } & \\cdots & x _ { 2 n } \\\\ \\vdots & \\vdots & & \\vdots \\\\ x _ { m 1 } & x _ { m 2 } & \\cdots & x _ { m n } \\end{array} \\right] \\tag{17.1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元素$x_{ij}$表示单词$w_{i}$在文本$d_{j}$中出现的频数或权值，$X$是一个稀疏矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "权值常用单词频率-逆文本频率（term frequency-inverse document frequency，TF-IDF）表示，定义为  \n",
    "\n",
    "$$\n",
    "\\text{TFIDF}_{ij} = \\frac{\\text{tf}_{ij}}{\\text{tf}_{\\bullet j}} \\log \\frac{\\text{df}}{\\text{df}_{i}},\\quad i=1,2,\\cdots,m;\\ j=1,2,\\cdots,n \\tag{17.2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{tf}_{ij}$ —— 单词$w_{i}$在文本$d_{j}$中出现的频数；  \n",
    "\n",
    "$\\text{tf}_{\\bullet j}$ —— 文本$d_{j}$中出现的所有单词的频数之和；  \n",
    "\n",
    "$\\text{df}_{i}$ —— 含有单词$w_{i}$的文本数； \n",
    "\n",
    "$\\text{df}$ —— 文本集合$D$的全部文本数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单词-文本矩阵$X$的第$j$列$x_{j}$表示文本$d_{j}$ \n",
    "\n",
    "$$\n",
    "x _ { j } = \\left[ \\begin{array} { c } x _ { 1 j } \\\\ x _ { 2 j } \\\\ \\vdots \\\\ x _ { m j } \\end{array} \\right] , \\quad j=1,2,\\cdots,n \\tag{17.3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这时矩阵$X$也可以写作$X=[x_{1}, x_{2}, \\cdots, x_{n}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个单词向量的内积或标准化内积（余弦）表示对应文本之间的语义相似度，文本$d_{i}$与$d_{j}$之间的相似度为  \n",
    "\n",
    "$$\n",
    "\\text{sim}(d_{i}, d_{j}) = x_{i} \\cdot x_{j}, \\quad \\frac{x_{i} \\cdot x_{j}}{\\| x_{i} \\|\\| x_{j} \\|}\n",
    "$$\n",
    "\n",
    "\n",
    "式中，$\\cdot \\ $表示向量内积，$\\|\\cdot\\|$表示向量范数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单词向量空间模型<font color=red>优点</font>: \n",
    "- 模型简单，计算效率高。因为单词向量通常是稀疏的，两个向量内积计算只需在其不同为零的维度上进行，需要的计算量很少，可以高效完成。 \n",
    "\n",
    "单词向量空间模型<font color=red>缺点</font>: 相似度计算不精确\n",
    "- 一词多义性\n",
    "- 多词一义性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.2 话题向量空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思想:**  \n",
    "\n",
    "一个文本一般含有若干个话题。如果两个文本的话题相似，那么两者的语义应该也相似。\n",
    "\n",
    "<font color=blue>不同的单词可以表示同一个话题（“airplane”与“aircraft”）；多义词（“apple”）可以表示不同的话题</font>，这样，话题模型就可以解决基于单词的模型存在的问题。  \n",
    "\n",
    "话题的个数通常远远小于单词的个数，话题向量空间模型更加抽象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 话题向量空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单词-文本矩阵$X$  \n",
    "\n",
    "$$\n",
    "X = \\left[ \\begin{array} { c c c c } x _ { 11 } & x _ { 12 } & \\cdots & x _ { 1 n } \\\\ x _ { 21 } & x _ { 22 } & \\cdots & x _ { 2 n } \\\\ \\vdots & \\vdots & & \\vdots \\\\ x _ { m 1 } & x _ { m 2 } & \\cdots & x _ { m n } \\end{array} \\right] = [x_{1}, x_{2}, \\cdots, x_{n}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设所有文本共含有$k$个话题。假设每个话题由一个定义在单词集合$W$上的$m$维向量表示，称为<font color=red>话题向量</font>，即   \n",
    "\n",
    "$$\n",
    "t _ { l } = \\left[ \\begin{array} { c } t _ { 1 l } \\\\ t _ { 2 l } \\\\ \\vdots \\\\ t _ { m l } \\end{array} \\right] ,\\quad l=1,2,\\cdots,k \\tag{17.6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t_{il}$表示单词$w_{i}$在话题$t_{l}$的权值。$k$个话题向量$t_{1}, t_{2}, \\cdots, t_{k}$张成一个话题向量空间（topic vector space）,记为$T$，称为<font color=red>单词-话题矩阵</font>  \n",
    "\n",
    "$$\n",
    "T = \\left[ \\begin{array} { c c c c } t _ { 11 } & t _ { 12 } & \\cdots & t _ { 1 k } \\\\ t _ { 21 } & t _ { 22 } & \\cdots & t _ { 2 k } \\\\ \\vdots & \\vdots & & \\vdots \\\\ t _ { m 1 } & t _ { m 2 } & \\cdots & t _ { m k } \\end{array} \\right]_{\\ m \\times k} = [t_{1}, t_{2}, \\cdots, t_{k}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 文本在话题向量空间中的表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本集合$D$的文本$d_{j}$，在单词向量空间$X$中由$x_{j}$表示， 将$x_{j}$投影到话题向量空间$T$中，得到一个向量$y_{j}$  \n",
    "\n",
    "$$\n",
    "y _ { j } = \\left[ \\begin{array} { c } y _ { 1 j } \\\\ \n",
    "y _ { 2 j } \\\\ \\vdots \\\\ y _ { k j } \\end{array} \\right] , \\quad j=1,2,\\cdots,n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y_{lj}$表示文本$d_{j}$在话题$t_{l}$的权值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵$Y$表示话题在文本中出现的情况，称为<font color=red>话题-文本矩阵</font>，记作  \n",
    "\n",
    "$$\n",
    "Y = \\left[ \\begin{array} { c c c c } y _ { 11 } & y _ { 12 } & \\cdots & y _ { 1 n } \\\\ y _ { 21 } & y _ { 22 } & \\cdots & y _ { 2 n } \\\\ \\vdots & \\vdots & & \\vdots \\\\ y _ { k 1 } & y _ { k 2 } & \\cdots & y _ { k n } \\end{array} \\right] = [y_{1}, y_{2}, \\cdots, y_{n}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 从单词向量空间到话题向量空间的线性变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在单词向量空间中的文本向量$x_{j}$可以通过它在话题空间中的向量$y_{j}$近似表示:  \n",
    "\n",
    "$$\n",
    "x_{j} \\approx y_{1j}t_{1} + y_{2j}t_{2} + \\cdots + y_{kj}t_{k}, \\quad j=1,2,\\cdots,n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用矩阵表示，就是<font color=blue>潜在语义分析</font>  \n",
    "\n",
    "$$\n",
    "X \\approx TY \\tag{17.11}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要进行潜在语言分析，需要同时决定两部分内容: \n",
    "1. <font color=blue>话题向量空间$T$</font>  \n",
    "2. <font color=blue>文本在话题空间的表示$Y$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='17_潜在语言分析.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在原始的单词向量空间，两个文本$d_{i}$与$d_{j}$的相似度可以由对应的向量内积表示，即$x_{i} \\bullet x_{j}$。经过潜在语义分析之后，在话题向量空间，文本相似度由对应的向量内积表示，即$y_{i} \\bullet y_{j}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2 潜在语义分析算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X = \\underset{T}{\\underbrace{U}} \\ \\underset{Y}{\\underbrace{\\Sigma V}}^{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2.1 SVD算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 单词-文本矩阵$X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定文本集合$D=\\left\\{d_{1}, d_{2}, \\cdots, d_{n}\\right\\}$和单词集合$w_{1}, w_{2}, \\cdots, w_{m}$。潜在语义分析首先将这些数据表示为单词-文本矩阵  \n",
    "\n",
    "$$\n",
    "X = \\left[ \\begin{array} { c c c c } x _ { 11 } & x _ { 12 } & \\cdots & x _ { 1 n } \\\\ x _ { 21 } & x _ { 22 } & \\cdots & x _ { 2 n } \\\\ \\vdots & \\vdots & & \\vdots \\\\ x _ { m 1 } & x _ { m 2 } & \\cdots & x _ { m n } \\end{array} \\right] \\tag{17.12}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 截断奇异值分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "潜在语义分析根据确定的话题个数$k$对$X$进行截断奇异值分解。  \n",
    "\n",
    "$$\n",
    "X \\approx U _ { k } \\Sigma _ { k } V _ { k } ^ { \\mathrm { T } } = \\left[ \\begin{array} { l l l l } u _ { 1 } & u _ { 2 } & \\cdots & u _ { k } \\end{array} \\right] \\left[ \\begin{array} { c c c c } \\sigma _ { 1 } & 0 & 0 & 0 \\\\ 0 & \\sigma _ { 2 } & 0 & 0 \\\\ 0 & 0 & \\ddots & 0 \\\\ 0 & 0 & 0 & \\sigma _ { k } \\end{array} \\right] \\left[ \\begin{array} { c } v _ { 1 } ^ { \\mathrm { T } } \\\\ v _ { 2 } ^ { \\mathrm { T } } \\\\ \\vdots \\\\ v _ { k } ^ { \\mathrm { T } } \\end{array} \\right]  \\tag{17.13}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 话题向量空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将$U_{k}$的每一列向量$u_{1},u_{2},\\cdots,u_{k}$表示一个话题，称作话题向量，这$k$个话题向量长成一个子空间，称为话题向量空间:  \n",
    "\n",
    "$$\n",
    "U_{k}=\\left[\\begin{array}{llll}\n",
    "u_{1} & u_{2} & \\cdots & u_{k}\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 文本的话题空间表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\Sigma _ { k } V _ { k } ^ { \\mathrm { T } } &=& \\left[ \\begin{array} { c c c c } \\sigma _ { 1 } & 0 & 0 & 0 \\\\ 0 & \\sigma _ { 2 } & 0 & 0 \\\\ 0 & 0 & \\ddots & 0 \\\\ 0 & 0 & 0 & \\sigma _ { k } \\end{array} \\right] \\left[ \\begin{array} { c } v _ { 1 } ^ { \\mathrm { T } } \\\\ v _ { 2 } ^ { \\mathrm { T } } \\\\ \\vdots \\\\ v _ { k } ^ { \\mathrm { T } } \\end{array} \\right]  \\\\\n",
    "&=& \\left[\\begin{array}{cccc}\n",
    "\\sigma_{1} v_{11} & \\sigma_{1} v_{21} & \\cdots & \\sigma_{1} v_{n 1} \\\\\n",
    "\\sigma_{2} v_{12} & \\sigma_{2} v_{22} & \\cdots & \\sigma_{2} v_{n 2} \\\\\n",
    "\\vdots & \\vdots & & \\vdots \\\\\n",
    "\\sigma_{k} v_{1 k} & \\sigma_{k} v_{2 k} & \\cdots & \\sigma_{k} v_{n k}\n",
    "\\end{array}\\right] \\tag{17.14}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有（17.14）可知，矩阵$X$的第$j$列向量$x_{j}$满足  \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "x_{j} & \\approx & U_{k}\\left(\\Sigma_{k} V_{k}^{\\mathrm{T}}\\right)_{j} \\\\\n",
    "&=& \\left[\\begin{array}{llll}\n",
    "u_{1} & u_{2} & \\cdots & u_{k}\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sigma_{1} v_{j 1} \\\\\n",
    "\\sigma_{2} v_{j 2} \\\\\n",
    "\\vdots \\\\\n",
    "\\sigma_{k} v_{j k}\n",
    "\\end{array}\\right] \\\\\n",
    "&=& \\sum_{l=1}^{k} \\sigma_{l} v_{j l} u_{l}, \\quad j=1,2, \\cdots, n \\tag{17.15}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "式(17.15)是文本$d_{j}$的近似表示。矩阵$(\\Sigma _ { k } V _ { k } ^ { \\mathrm { T } })$的每一个列向量  \n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{c}\n",
    "\\sigma_{1} v_{11} \\\\\n",
    "\\sigma_{2} v_{12} \\\\\n",
    "\\vdots \\\\\n",
    "\\sigma_{k} v_{1 k}\n",
    "\\end{array}\\right], \\quad\\left[\\begin{array}{c}\n",
    "\\sigma_{1} v_{21} \\\\\n",
    "\\sigma_{2} v_{22} \\\\\n",
    "\\vdots \\\\\n",
    "\\sigma_{k} v_{2 k}\n",
    "\\end{array}\\right], \\cdots, \\quad\\left[\\begin{array}{c}\n",
    "\\sigma_{1} v_{n 1} \\\\\n",
    "\\sigma_{2} v_{n 2} \\\\\n",
    "\\vdots \\\\\n",
    "\\sigma_{k} v_{n k}\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是一个文本在话题向量空间的表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3 非负矩阵分解算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3.1 非负矩阵分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若一个矩阵的所有元素非负，则称该矩阵为非负矩阵，若$X$是非负矩阵，记作$X\\geq 0$.  \n",
    "\n",
    "给定一个非负矩阵$X$，找到两个非负矩阵$W\\geq 0$和$H\\geq 0$，使得  \n",
    "\n",
    "$$\n",
    "X_{m \\times n} \\approx W_{m \\times k}H_{k \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "称为非负矩阵分解。假设$k < \\min(m,n)$，即$W,H$小于原始矩阵$X$，所以非负矩阵分解是对原始数据的压缩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵$X$的第$j$列向量$x_{j}$满足  \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "x_{j} &\\approx& Wh_{j} \\\\\n",
    "&=& \\left[\\begin{array}{llll}w_{1} & w_{2} & \\cdots & w_{k}\\end{array}\\right]\\left[\\begin{array}{c}h_{1 j} \\\\ h_{2 j} \\\\ \\vdots \\\\ h_{k j}\\end{array}\\right] \\\\\n",
    "&=& \\sum_{l=1}^{k}h_{l j}w_{l} ,\\quad j=1,2,\\cdots,n \\tag{17.18}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "式（17.18）表示，矩阵$X$的第$j$列$x_{j}$可以由矩阵$W$的$k$个列向量$w_{l}$的线性组合逼近。线性组合的系数是矩阵$H$的第$j$列$h_{j}$的元素。称$W$为基矩阵，$H$为系数矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3.2 潜在语言分析模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_{m \\times n} \\approx W_{m \\times k}H_{k \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令$W=\\left[\\begin{array}{llll}w_{1} & w_{2} & \\cdots & w_{k}\\end{array}\\right]$为话题向量空间，令$H=\\left[\\begin{array}{llll}h_{1} & h_{2} & \\cdots & h_{n}\\end{array}\\right]$为文本在话题向量空间的表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3.2 非负矩阵分解的形式化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非负矩阵分解可以形式化为最优问题求解。首先定义损失函数。  \n",
    "\n",
    "- 平方损失\n",
    "$$\n",
    "\\|A-B\\|^{2}=\\sum_{i, j}\\left(a_{i j}-b_{i j}\\right)^{2}\\tag{17.20}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 散度（divergence）\n",
    "\n",
    "$$\n",
    "D(A \\| B)=\\sum_{i, j}\\left(a_{i j} \\log \\frac{a_{i j}}{b_{i j}}-a_{i j}+b_{i j}\\right) \\tag{17.21}\n",
    "$$  \n",
    "下界是0，当且仅当$A=B$时达到下界。当$\\sum_{i, j} a_{i j}=\\sum_{i, j} b_{i j}=1$时，损失函数退化为KL散度或相对熵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写成最优化的形式  \n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{matrix}\n",
    " \\min_{W, H} \\ \\|X-W H\\|^{2} \\\\\n",
    "  s.t. \\quad W, H \\geqslant 0\n",
    "\\end{matrix}\\right. \\tag{17.22}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{matrix}\n",
    " \\min_{W, H}\\ D(X\\| WH) \\\\\n",
    "  s.t. \\quad W, H \\geqslant 0\n",
    "\\end{matrix}\\right. \\tag{17.23}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3.4 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于最优化问题(17.22)和(17.23)，目标函数只对变量$W$和$H$之一的凸函数，而不是同时对两个变量的凸函数，因此找到全局最优比较困难，可以通过数值优化方法求局部最优。  \n",
    "\n",
    "**梯度下降法**比较容易，但收敛速度慢。  \n",
    "\n",
    "**共轭梯度法**收敛速度快，但实现比较复杂。  \n",
    "\n",
    "Lee和Seung提出基于“乘法更新规则”的优化算法，交替对$W$和$H$进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定理17.1 \n",
    "平方损失$\\|X-W H\\|^{2}$对下列乘法更新规则 \n",
    "\n",
    "$$\n",
    "H_{l j} \\leftarrow H_{l j} \\frac{\\left(W^{\\mathrm{T}} X\\right)_{l j}}{\\left(W^{\\mathrm{T}} W H\\right)_{l j}} \\tag{17.33}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{i l} \\leftarrow W_{i l} \\frac{\\left(X H^{\\mathrm{T}}\\right)_{i l}}{\\left(W H H^{\\mathrm{T}}\\right)_{i l}} \\tag{17.34}\n",
    "$$\n",
    "\n",
    "是非增的。当且仅当$W$和$H$是平方损失函数的稳定点时函数的更新不变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定理17.2 \n",
    "\n",
    "散度损失$D(X-WH)$对下列更新规则  \n",
    "\n",
    "$$\n",
    "H_{l j} \\leftarrow H_{l j} \\frac{\\sum_{i}\\left[W_{i l} X_{i j} /(W H)_{i j}\\right]}{\\sum_{i} W_{i l}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{i l} \\leftarrow W_{i l} \\frac{\\sum_{j}\\left[H_{l j} X_{i j} /(W H)_{i j}\\right]}{\\sum_{j} H_{l j}}\n",
    "$$\n",
    "\n",
    "是非增的。当且仅当$W$和$H$是散度损失函数的稳定点时函数的更新不变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 算法17.1 （非负矩阵分解的迭代算法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入: 单词-文本矩阵$X\\geq 0$，文本集合的话题个数$k$，最大迭代次数$t$；  \n",
    "\n",
    "输出: 话题矩阵$W$，文本表示矩阵$H$. \n",
    "\n",
    "（1）初始化  \n",
    "\n",
    "$W \\geq 0$，并对$W$的每一列数据归一化；\n",
    "\n",
    "$H \\geq 0$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）迭代: 对迭代次数由1到t执行下列步骤:\n",
    "- 更新$W$的元素，对$l:1\\rightarrow k$，$i:1\\rightarrow m$按式(17.33)更新$W_{il}$;  \n",
    "\n",
    "- 更新$H$的元素，对$l:1\\rightarrow k$，$j:1\\rightarrow n$按式(17.34)更新$W_{lj}$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
