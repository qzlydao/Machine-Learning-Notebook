{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 第10章 隐马尔科夫模型\n",
    "\n",
    "## 10.1 HMM的基本概念\n",
    "\n",
    "#### 1. 引例\n",
    "\n",
    "我们假设一个赌场里来了一个老千，他带有两种作弊骰子，分别记为骰子2，骰子3，骰子2掷出较小点数的概率较大，骰子3掷出较大点数的概率更大。所以现在我们有三种骰子，分别是赌场正常骰子1，和两种作弊骰子2，骰子3。这就是三种隐状态，因为我们不知道老千每次使用的是哪种骰子。但是我们知道老千切换骰子的习惯，可以表示如下图：\n",
    "\n",
    "<img src=\"10.1_骰子例子.jpg\" style=\"zoom:50%;\" />\n",
    "\n",
    "这个概率就是`状态转移概率`，表明了隐状态从一种状态转换到另一种状态的概率，可以写成如下矩阵的形式：\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0.15  & 0.45 & 0.40 \\\\\n",
    " 0.30 & 0.20 & 0.50 \\\\\n",
    " 0.20 & 0.50 & 0.30\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "我们也知道三种骰子掷出1~6点的概率分别如下：\n",
    "\n",
    "<img src=\"10.1_骰子例子2.jpg\" alt=\"10.1_骰子例子2\" style=\"zoom:50%;\" />\n",
    "\n",
    "这些概率称作==观测概率==，观测概率也可用矩阵形式表示如下：\n",
    "$$\n",
    "B = \\begin{bmatrix}\n",
    " 0.16 & 0.16 & 0.16 & 0.16 & 0.16 & 0.16 \\\\\n",
    " 0.06 & 0.06 & 0.06 & 0.06 & 0.06 & 0.70 \\\\\n",
    " 0.40 & 0.20 & 0.15 & 0.05 & 0.05 & 0.05\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "以上状态转移概率矩阵、观测概率矩阵和初始概率分布就囊括了整个HMM模型。\n",
    "\n",
    "\n",
    "\n",
    "#### 2. 定义\n",
    "\n",
    "<img src=\"10.1_HMM示例.png\" alt=\"10.1_HMM示例\" style=\"zoom:50%;\" />\n",
    "\n",
    "隐状态序列 $I=(i_{1},i_{2}, \\cdots, i_{T})$\n",
    "\n",
    "观测序列 $O=(o_{1}, o_{2}, \\cdots, o_{T})$\n",
    "\n",
    "隐状态可能取值集合：$Q={q_{1}, q_{2}, \\cdots, q_{N}}$\n",
    "\n",
    "观测值的集合： $V={v_{1}, v_{2}, \\cdots, v_{M}}$\n",
    "\n",
    "\n",
    "\n",
    "#### 3. 三要素\n",
    "\n",
    "`状态转移矩阵A：`\n",
    "$$\n",
    "A = [a_{ij}]_{N \\times N} \\\\\n",
    "a_{ij} = P(i_{t+1}=q_{j} | i_{t} = q_{i} ) \\quad \\quad i,j=1,2, \\cdots , N; \n",
    "$$\n",
    "是在时刻 $t$ 处于状态 $q_{i}$ 的条件下，在下一时刻 $t+1$ 转移到状态 $q_{j}$的概率。\n",
    "\n",
    "\n",
    "\n",
    "`观测概率矩阵B：`\n",
    "$$\n",
    "B = [b_{j}(k)]_{N \\times M} \\\\\n",
    "b_{j}(k) = P(o_{t} = v_{k} | i_{t}=q_{j}) \\quad \\quad k=1,2, \\cdots,M; \\quad j=1,2,\\cdots,N\n",
    "$$\n",
    "表示，$t$ 时刻处于状态$q_{j}$ 的条件下生成观测 $v_{k}$ 的概率。\n",
    "\n",
    "\n",
    "\n",
    "`初始状态概率向量$\\pi$：`\n",
    "$$\n",
    "\\pi = (\\pi_{i}) \\\\\n",
    "\\pi_{i} = P(i_1=q_{i}) \\quad  \\quad  i=1,2,\\cdots,N\n",
    "$$\n",
    "表示$t=1$时刻处于状态 $q_{i}$ 的概率。\n",
    "\n",
    "\n",
    "\n",
    "$A,B,\\pi$ 称为隐马尔科夫模型的**三要素**，记作：\n",
    "$$\n",
    "\\lambda = (A,B,\\pi)\n",
    "$$\n",
    "\n",
    "\n",
    "#### 4. 两个基本假设\n",
    "\n",
    "1. `齐次马尔科夫性假设：`\n",
    "\n",
    "$$\n",
    "P(i_{t}|i_{t-1},o_{i-1}, \\cdots, i_{1},o_{1}) = P(i_{t}|i_{t-1})\n",
    "$$\n",
    "\n",
    "2. `观测独立性假设：`\n",
    "\n",
    "$$\n",
    "P(o_{t}|i_{1},o_{1},\\cdots,i_{t-1},o_{t-1},i_{t+1},o_{t+1},\\cdots, i_{T},o_{T}) = P(o_{t}|i_{t})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### 5. 三个基本问题\n",
    "\n",
    "1. **概率计算问题：** 即求 $P(O|\\lambda)$， 对应前向、后向算法\n",
    "\n",
    "2. **学习问题：**\n",
    "   $$\n",
    "   \\hat{\\lambda} = \\underset{\\lambda}{\\text{argmax}} P(O|\\lambda)\n",
    "   $$\n",
    "   对应Baum-Welch算法求解\n",
    "\n",
    "3. **预测问题：**也称解码（decoding）问题。\n",
    "   $$\n",
    "   I^{*} = (i_{1}^{*},i_{2}^{*},\\cdots,i_{T}^{*}) = \\underset{I}{\\text{argmax}}P(I|O,\\lambda)\n",
    "   $$\n",
    "   对应Viterbi算法求解。\n",
    "\n",
    "\n",
    "\n",
    "## 10.2  概率计算算法\n",
    "\n",
    "给定模型$\\lambda = (A,B,\\pi)$ 和观测序列 $O=(o_{1},o_{2}, \\cdots, o_{T})$，计算观测序列$O$ 出现的概率 $P(O|\\lambda)$.\n",
    "\n",
    "### 10.2.1 直接计算法\n",
    "\n",
    "先求各状态序列$I$ 和观测序列 $O$ 的联合概率 $P(O,I|\\lambda)$， 然后对所有可能的状态序列求和，得到$P(O|\\lambda)$ .\n",
    "\n",
    "首先：\n",
    "\n",
    "$$\n",
    "P(I|\\lambda) = \\pi_{i_1}a_{i_1i_2} \\cdots a_{i_{T-1}i_{T}}\n",
    "$$\n",
    "\n",
    "其次：\n",
    "\n",
    "$$\n",
    "P(O|I,\\lambda) = b_{i_1}(o_1)b_{i_2}(o_2) \\cdots b_{i_T}(o_{T})\n",
    "$$\n",
    "\n",
    "所以，$O、I$ 的联合概率为：\n",
    "\n",
    "$$\n",
    "P(O,I|\\lambda) = P(O|I,\\lambda)P(I|\\lambda) = \\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2) \\cdots a_{i_{T-1}i_{T}}b_{i_T}(o_{T})\n",
    "$$\n",
    "\n",
    "\n",
    "对所有可能状态的$I$求和，得到$P(O|\\lambda)$:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "P(O|\\lambda) &=& \\sum_{I}P(O|I,\\lambda)P(I|\\lambda) \\\\\n",
    "&=& \\sum_{i_1i_2 \\cdots i_T} \\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2) \\cdots a_{i_{T-1}i_{T}}b_{i_T}(o_{T})\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "长度为$T$ 的状态序列，所有可能的序列数为$N^{T}$ ，因此总的时间复杂度为$O(TN^{T})$。\n",
    "\n",
    "很明显，时间复杂度太高，不可行。\n",
    "\n",
    "\n",
    "\n",
    "### 10.2.2 前向算法\n",
    "\n",
    " <img src=\"10.2_前向算法.png\" alt=\"10.2_前向算法\" style=\"zoom:50%;\" />\n",
    "\n",
    "#### 1. 前向概率\n",
    "\n",
    "$t$ 时刻的前向概率定义如上图所示：\n",
    "$$\n",
    "\\alpha_{t}(i) = P(O_{1},o_{2},o_{t},i_{t}=q_{i}|\\lambda)\n",
    "$$\n",
    "\n",
    "\n",
    "#### 2. 算法\n",
    "\n",
    "输入：模型$\\lambda $， 观测序列$O$；\n",
    "\n",
    "输出：观测序列概率$P(O|\\lambda)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 初值：\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\alpha_{1}(i) &=& P(o_{1}, i_{1} = q_{i}|\\lambda) = P(i_{1} = q_{i}|\\lambda) \\cdot P(o_{1}|i_{1} = q_{i}, \\lambda) \\\\\n",
    "&=& \\pi_{i}b_{i}(o_{1}) \\quad \\quad i=1,2,\\cdots,N\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)递推： 对t=1,2,T-1:\n",
    "\n",
    "$$\n",
    "\\alpha_{t+1}(i) = \\left[ \\sum_{j=1}^{N}  \\alpha_{t}(j)a_{ji}\\right] b_{i}(o_{t+1})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)终止：\n",
    "\n",
    "$$\n",
    "P(O|\\lambda) = \\sum_{i=1}^{N} \\alpha_{T}(i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前向算法高效的关键是：<font color=red>**其局部计算前向概率，然后利用路径结构将前向概率“递推”到全局。**</font>  \n",
    "\n",
    "在$t$ 时刻，需计算$\\alpha_{t}(i)$ 的$N$ 个值，在$t+1$ 时刻，计算$\\alpha_{t+1}(i)$的$N$ 个值时需利用前一时刻的$N$个结果，考虑序列长度为$T$，因此总的时间复杂度为$O(TN^{2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3  后向算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 后向概率\n",
    "$t$ 时刻的后向概率为：\n",
    "$$\n",
    "    \\beta_{t}(i) = P(o_{t+1}, o_{t+2}, \\cdots, o_{T} | i_{t}=q_{i}, \\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 算法\n",
    "\n",
    "(1)初值\n",
    "\n",
    "$$\n",
    "\\beta_{T}(i) = 1, \\quad i=1,2,\\cdots,N\n",
    "$$\n",
    "\n",
    "(2)递推，对于$t=T-1,T-2,\\cdots, 1$\n",
    "$$\n",
    "\\beta_{t}(i) = \\sum_{j=1}^{N}a_{ij}b_{j}(o_{t+1})\\beta_{t+1}(j)\n",
    "$$\n",
    "\n",
    "(3)终止\n",
    "$$\n",
    "P(O|\\lambda) = \\sum_{i=1}^{N} \\pi_{i}b_{i}(o_{1})\\beta_{1}(i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4 一些概率和期望值的计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 给定模型$\\lambda$ 和 观测$O$，在时刻$t$ 处于状态 $ q_{i} $ 的概率，记为：\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\gamma_{t}(i) &=& P(i_{t}=q_{i}|O,\\lambda) \\\\\n",
    "&=& \\frac{\\alpha_{t}(i)\\beta_{t}(i)}{\\sum_{j=1}^{N}\\alpha_{t}(j)\\beta_{t}(j)}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 给定$\\lambda, O$ ，在时刻$t$ 处于状态$q_{i}$ 且在时刻$t+1$ 处于状态 $q_{j}$ 的概率，记为：\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\xi _{t}(i,j) &=& P(i_{t}=q_{i}, i_{t+1}=q_{j}|O,\\lambda) \\\\\n",
    "&=& \\frac{\\alpha_{t}(i)a_{ij}b_{j}(o_{t+1})\\beta_{t+1}(j)}{\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{t}(i)a_{ij}b_{j}(o_{t+1})\\beta_{t+1}(j)}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 在观测$O$下状态$i$出现的期望：\n",
    "$$\n",
    "\\sum_{i=1}^{T}\\gamma_{t}(i)\n",
    "$$\n",
    "\n",
    "4. 在观测$O$下由状态$i$转移的期望：\n",
    "$$\n",
    "\\sum_{i=1}^{T-1}\\gamma_{t}(i)\n",
    "$$\n",
    "\n",
    "5. 在观测$O$下由状态$i$转移到状态$j$的期望：\n",
    "$$\n",
    "\\sum_{j=1}^{T-1}\\xi_{t}(i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 学习算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若训练数据包括：观测序列和对应的状态序列，则是监督学习；\n",
    "\n",
    "若训练数据只有观测序列，而无状态序列，则是无监督学习，对应Baum-Welch算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 监督学习方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设给定数据集包含$S$ 个长度相同的观测序列和对应的状态序列${(O_1, I_1), (O_2, I_2), \\cdots, (O_s, I_s)}$，那么可以用MLE估计参数：\n",
    "\n",
    "1. 设样本中时刻$t$ 处于状态$i$，时刻$t+1$ 处于状态$j$ 的频数是$A_{ij}$，则\n",
    "$$ \n",
    "\\hat{a}_{ij}= \\frac{ A_{ij} }{ \\sum_{j=1}^{N} A_{ij} }\n",
    "$$\n",
    "\n",
    "2. 设样本中状态为$j$ 并观测为$k$ 的频数为$B_{jk}$，则\n",
    "$$\n",
    "\\hat{b}_{j}(k) = \\frac{ B_{jk} }{ \\sum_{k=1}^{M} B_{jk} }\n",
    "$$\n",
    "\n",
    "3. $\\hat{\\pi}_{i}$ 为S个样本中$q_{i}$的频率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 Baum-Welch算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设给定训练数据只有$S$个长度为$T$ 的观测序列${O_1, O_2, \\cdots, O_T}$，而没有对应的状态序列。\n",
    "\n",
    "HMM模型事实上是一个含有隐变量的概率模型：\n",
    "$$\n",
    "P(O|\\lambda) = \\sum_{I} P(O|I, \\lambda)P(I|\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 确定完全数据的对数似然函数\n",
    "\n",
    "    完全数据$(O,I)=(o_1,o_2, \\cdots, o_T,i_1,i_2, \\cdots, i_T)$\n",
    "    \n",
    "    完全数据的对数似然函数是 $\\log{P(O,I|\\lambda)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. EM算法的E步：求Q函数$Q(\\lambda,\\hat{\\lambda})$\n",
    "\n",
    "    就是求完全数据对数似然函数$\\log{P(O,I|\\lambda)}$ 在后验 $P(I|O,\\lambda)$ 上的分布：\n",
    "    \n",
    "    $$\n",
    "    \\begin{eqnarray*}\n",
    "    Q(\\lambda, \\hat{\\lambda}) &=& E_{I} \\left[ \\log{P(O,I|\\lambda)|O, \\bar{\\lambda}} \\right] \\\\\n",
    "    &=& \\sum_{I} \\log{P(O,I|\\lambda)} \\cdot P(I|O, \\bar{\\lambda}) \\\\\n",
    "    &=& \\sum_{I} \\log{P(O,I|\\lambda)} \\cdot \\frac{P(I,O| \\bar{\\lambda}) }{ \\color{grey}{P(O| \\bar{\\lambda}) }} \\\\\n",
    "    &=& \\sum_{I} \\log{P(O,I|\\lambda)} \\cdot P(O, I| \\bar{\\lambda}) \n",
    "    \\end{eqnarray*}\n",
    "    $$\n",
    "    \n",
    "    将：\n",
    "    \n",
    "    $$\n",
    "    P(O,I|\\lambda) = P(O|I,\\lambda)P(I|\\lambda) = \\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2) \\cdots a_{i_{T-1}i_{T}}b_{i_T}(o_{T})\n",
    "    $$\n",
    "    \n",
    "    带入上式，$Q(\\lambda, \\hat{\\lambda})$可写成：\n",
    "    \n",
    "    $$\n",
    "    \\begin{eqnarray*}\n",
    "    Q(\\lambda, \\hat{\\lambda}) &=& \\sum_{I}\\log{\\pi_{i_{1}}}P(O,I|\\bar{\\lambda}) \\\\\n",
    "    &+& \\sum_{I} \\left( \\sum_{t=1}^{T-1} \\log{ a_{i_{t}i_{t+1}} }  \\right)P(O,I|\\bar{\\lambda}) + \\sum_{I} \\left( \\sum_{t=1}^{T} \\log{ b_{i_{t}}(o_{t}) }  \\right)P(O,I|\\bar{\\lambda})\n",
    "    \\end{eqnarray*}\n",
    "    $$\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. EM算法的M步：极大化$Q$函数，求模型参数$A,B,\\pi$.\n",
    "\n",
    "    由于要极大化的参数在上式中单独地出现在3个项中，因此只需对各项分别极大化。\n",
    "    \n",
    "    利用拉格朗日乘数法，对拉格朗日函数求偏导，可得到对应的参数值：\n",
    "    \n",
    "    (1)\n",
    "    $$\n",
    "    \\pi_{i} = \\frac{ P(O,i_1=i|\\bar{\\lambda}) }{ P(O|\\bar{\\lambda}) }\n",
    "    $$\n",
    "    \n",
    "    (2)\n",
    "    $$\n",
    "    a_{ij} = \\frac{ \\sum_{t=1}^{T-1}P(O,i_{t}=i,i_{t+1}=j|\\bar{\\lambda}) }{ \\sum_{t=1}^{T-1}P(O,i_{t}=i|\\bar{\\lambda}) }\n",
    "    $$\n",
    "    \n",
    "    (3)\n",
    "    $$\n",
    "    b_{j}(k) = \\frac{ \\sum_{t=1}^{T}P( O,i_{t}=j | \\bar{\\lambda})I(o_{t}=v_{k}) }{ \\sum_{t=1}^{T}P( O,i_{t}=j|\\bar{\\lambda} ) }\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 Baum-Welch模型参数估计公式\n",
    "\n",
    "将$\\pi_{i}, a_{ij}, b_{j}(k)$ 分别用$\\gamma_{t}(i)，\\xi_{t}(i,j)$表示，可写成如下公式：\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "a_{ij} &=& \\frac{ \\sum_{t=1}^{T-1}\\xi_{t}(i,j) }{ \\sum_{t=1}^{T-1}\\gamma_{t}(i) } \\\\\n",
    "b_{j}(k) &=& \\frac{ \\sum_{t=1,o_{t}=v_{k}}^{T}\\gamma_{t}(i) }{ \\sum_{t=1}^{T}\\gamma_{t}(i) } \\\\\n",
    "\\pi_{i} &=& \\gamma_{1}(i)\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baum-Welch算法\n",
    "输入：观测数据$O=(o_{1}, o_{2}, \\cdots, o_{T})$;  \n",
    "\n",
    "输出：$\\lambda = (A,B,\\pi)$\n",
    "\n",
    "(1)初始化\n",
    "\n",
    "对于$n=0$，选取$a_{ij}^{(0)}, b_{j}(k)^{(0)}, \\pi_{i}^{(0)}$ ，得到模型$\\lambda^{(0)} = (A^{(0)}, B^{(0)}, \\pi^{(0)})$\n",
    "\n",
    "(2)递推，对于$n=1,2,\\cdots$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "a_{ij}^{(n+1)} &=& \\frac{ \\sum_{t=1}^{T-1}\\xi_{t}(i,j) }{ \\sum_{t=1}^{T-1}\\gamma_{t}(i) } \\\\\n",
    "b_{j}(k)^{(n+1)} &=& \\frac{ \\sum_{t=1,o_{t}=v_{k}}^{T}\\gamma_{t}(i) }{ \\sum_{t=1}^{T}\\gamma_{t}(i) } \\\\\n",
    "\\pi_{i}^{(n+1)} &=& \\gamma_{1}(i)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "(3)终止\n",
    "\n",
    "得到模型参数$\\lambda^{(n+1)} = (A^{(n+1)}, B^{(n+1)}, \\pi^{(n+1)})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 预测算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已知模型参数$\\lambda$ 和观测数据$O$，求条件概率$P(I|O)$最大的状态序列$T=(i_1, i_2, \\cdots, i_T)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1 近似算法\n",
    "\n",
    "近似算法的思想是： <font color=blue>在每个时刻$t$ 选择在该时刻最有可能的状态$i_{t}^{*}$，从而得到一个状态序列$I^* = (i_{1}^{*}, i_{2}^{*}, \\cdots, i_{T}^{*})$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在10.2.4中已求出：\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\gamma_{t}(i) &=& P(i_{t}=q_{i}|O,\\lambda) \\\\\n",
    "&=& \\frac{\\alpha_{t}(i)\\beta_{t}(i)}{\\sum_{j=1}^{N}\\alpha_{t}(j)\\beta_{t}(j)}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "因此每一个时刻$t$ 最有可能出现的$i_{t}^*$ 是：\n",
    "$$\n",
    "i_{t}^* = \\text{arg}\\max_{1 \\leq i \\leq N}[\\gamma_{t}(i)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近似算法的缺点：<font color=blue>不能保证预测的状态序列整体是最有可能的状态序列，因为预测的状态序列可能有实际不发生的部分。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2 Viterbi算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi算法实际上是用动态规划解HMM的预测问题。\n",
    "\n",
    "定义$\\delta_{t}(i)$为时刻$t$ 状态为$i$ 的所有单个路径$(i_{1},i_2,\\cdots,i_t)$中概率最大的值：\n",
    "$$\n",
    "\\delta_{t}(i) = \\max_{i_1, \\cdots, \\color{red}{i_{t-1}}}P(i_t=i,i_{t-1},\\cdots, i_{1},o_{1},\\cdots,o_{t}|\\lambda)\n",
    "$$\n",
    "\n",
    "由定义可得$\\delta$的递推式：\n",
    "$$\n",
    "\\delta_{t+1}(i) = \\max_{1 \\leq j \\leq N}\\left[ \\delta_{t}(j)a_{ji} \\right]b_{i}(o_{t+1})\n",
    "$$\n",
    "\n",
    "定义$\\psi_{t}(i)$ 为t时刻状态为i的所有单个路径$i_1,\\cdots,i_{t-1},i_{t}$中概率最大路径的第<font color=red>t-1</font>个节点：\n",
    "$$\n",
    "\\psi_{t}(i) = \\text{arg} \\max_{1 \\leq j \\leq N}[\\delta_{t-1}(j)a_{ji}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi算法\n",
    "(1)初始化\n",
    "$$\n",
    "\\delta_{1}(i) = \\pi_{i}b_{i}(o_{1}) \\\\\n",
    "\\psi_{1}(i) = 0\n",
    "$$\n",
    "\n",
    "(2)递推，对t=2,3,...,T\n",
    "$$\n",
    "\\delta_{t}(i) = \\max_{1 \\leq j \\leq N}\\left[ \\delta_{t-1}(j)a_{ji} \\right]b_{i}(o_{t}) \\\\\n",
    "\\psi_{t}(i) = \\text{arg} \\max_{1 \\leq j \\leq N}[\\delta_{t-1}(j)a_{ji}]\n",
    "$$\n",
    "\n",
    "(3)终止\n",
    "$$\n",
    "P^* = \\max_{1 \\leq i \\leq N} \\delta_{T}(i) \\\\\n",
    "i_{T}^{*} = \\text{arg} \\max_{1 \\leq i \\leq N} \\left[ \\delta_{T}(i) \\right]\n",
    "$$\n",
    "\n",
    "(4)最优路径回溯，对t=T-1,T-2,...,1\n",
    "$$\n",
    "i_{t}^{*} =\\psi_{t+1}(i_{i+1}^{*})\n",
    "$$\n",
    "\n",
    "于是得到最优路径$I^* = (i_{1}^{*}, i_{2}^{*}, \\cdots, i_{T}^{*})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "package chapter10_HMM;\n",
    "\n",
    "/**\n",
    " * Created with IntelliJ IDEA.\n",
    " * Description:\n",
    " * User: liuqiang\n",
    " * Date: 2020-12-22 11:47\n",
    " */\n",
    "public class HMM {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        double[][] A = {\n",
    "                {0.5, 0.2, 0.3},\n",
    "                {0.3, 0.5, 0.2},\n",
    "                {0.2, 0.3, 0.5}};\n",
    "\n",
    "        double[][] B = {\n",
    "                {0.5, 0.5},\n",
    "                {0.4, 0.6},\n",
    "                {0.7, 0.3}\n",
    "        };\n",
    "\n",
    "        double[] pi = {0.2, 0.4, 0.4};\n",
    "\n",
    "        int[] O = {0, 1, 0};\n",
    "\n",
    "        // 前向算法\n",
    "        double prob = forward(A, B, pi, O);\n",
    "        System.out.println(String.format(\"观测序列的概率为:%4f\", prob));\n",
    "\n",
    "        // 维特比算法\n",
    "        int[] path = viterbi(A, B, pi, O);\n",
    "        System.out.print(\"最优状态路径：\");\n",
    "        for (int i : path) {\n",
    "            System.out.printf(\"%d \", i);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * 概率计算算法之前向算法\n",
    "     *\n",
    "     * @param A  状态转移矩阵\n",
    "     * @param B  观测概率矩阵\n",
    "     * @param pi 初始状态向量\n",
    "     * @param O  观测序列\n",
    "     * @return\n",
    "     */\n",
    "    public static double forward(double[][] A, double[][] B, double[] pi, int[] O) {\n",
    "        int N = A.length; // 状态数N\n",
    "        int M = B.length; // 观测数\n",
    "        int T = O.length; // 序列长度\n",
    "        double prob = 0.0; // 观测序列O的概率\n",
    "\n",
    "        // 定义前向概率矩阵: T × N\n",
    "        double[][] alpha = new double[T][N];\n",
    "\n",
    "        // 计算初值\n",
    "        for (int i = 0; i < N; i++) {\n",
    "            alpha[0][i] = pi[i] * B[i][O[0]];\n",
    "        }\n",
    "\n",
    "        // 递推计算t=2,3,...,T\n",
    "        for (int t = 1; t < T; t++) {\n",
    "            for (int j = 0; j < N; j++) {\n",
    "                double tmp = 0.0;\n",
    "                for (int k = 0; k < N; k++) {\n",
    "                    tmp += alpha[t - 1][k] * A[k][j];\n",
    "                }\n",
    "                alpha[t][j] = tmp * B[j][O[t]];\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 打印alpha矩阵\n",
    "        for (int i = 0; i < T; i++) {\n",
    "            for (int j = 0; j < N; j++) {\n",
    "                System.out.printf(\"%4f \", alpha[i][j]);\n",
    "                if (j == N - 1) {\n",
    "                    System.out.println();\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 将T时刻的所有alpha求和，得到概率\n",
    "        for (int i = 0; i < M; i++) {\n",
    "            prob += alpha[T - 1][i];\n",
    "        }\n",
    "\n",
    "        return prob;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * viterbi算法，计算最优路径\n",
    "     *\n",
    "     * @param A  状态转移矩阵 N×N\n",
    "     * @param B  观测概率矩阵 N×M\n",
    "     * @param pi 初始状态向量 N×1\n",
    "     * @param O  观测序列 T×1\n",
    "     * @return 状态序列 T×1\n",
    "     */\n",
    "    public static int[] viterbi(double[][] A, double[][] B, double[] pi, int[] O) {\n",
    "        int N = A.length; // 状态数N\n",
    "        int M = B.length; // 观测数\n",
    "        int T = O.length; // 序列长度\n",
    "\n",
    "        // 定义状态序列\n",
    "        int[] I = new int[T];\n",
    "\n",
    "        // 定义delta矩阵\n",
    "        double[][] delta = new double[T][N];\n",
    "\n",
    "        // 定义psi矩阵\n",
    "        int[][] psi = new int[T][N];\n",
    "\n",
    "        // 1. 初始化\n",
    "        for (int i = 0; i < N; i++) {\n",
    "            delta[0][i] = pi[i] * B[i][O[0]];\n",
    "            psi[0][i] = 0;\n",
    "        }\n",
    "\n",
    "        // 2. 递推\n",
    "        for (int t = 1; t < T; t++) {\n",
    "            for (int i = 0; i < N; i++) { // 对N个状态\n",
    "                delta[t][i] = 0;\n",
    "                double psiTmp = -1.0;\n",
    "                for (int j = 0; j < N; j++) {\n",
    "                    // 计算delta\n",
    "                    double tmp = delta[t - 1][j] * B[i][O[t]];\n",
    "                    if (tmp > delta[t][i]) {\n",
    "                        delta[t][i] = tmp;\n",
    "                    }\n",
    "\n",
    "                    // 计算psi\n",
    "                    double tmp2 = delta[t - 1][j] * A[j][i];\n",
    "                    if (tmp2 > psiTmp) {\n",
    "                        psi[t][i] = j;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 3. 终止，得到T时刻delta最大的状态iT*\n",
    "        double maxPro = 0.0;\n",
    "        int iT = -1;\n",
    "        for (int i = 0; i < N; i++) {\n",
    "            if (delta[T - 1][i] > maxPro) {\n",
    "                iT = i;\n",
    "            }\n",
    "        }\n",
    "        I[T - 1] = iT;\n",
    "\n",
    "        // 4. 从T-1时刻往前回溯，得到路径I*\n",
    "        for (int t = T - 2; t > -1; t--) {\n",
    "            I[t] = psi[t + 1][I[t + 1]];\n",
    "        }\n",
    "        return I;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
