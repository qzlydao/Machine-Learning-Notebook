{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章 EM算法及其推广"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EM算法是一种迭代算法，用于含有隐变量的概率模型的极大似然估计，或极大后验概率估计。   \n",
    "\n",
    "2. E步:求期望；M步:求最大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 EM算法的引入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1 EM算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "符号说明:  \n",
    "\n",
    "$Y$ 表示观测随机变量的数据；  \n",
    "\n",
    "$Z$ 表示隐随机变量的数据；  \n",
    "\n",
    "$Y,Z$ 连在一起表示完全数据；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM算法通过迭代求$L(\\theta) = \\log P(Y|\\theta) = \\log \\sum_{Z} P(Y,Z|\\theta) = \\log \\sum_{Z}P(Z|\\theta)P(Y|Z, \\theta)$的极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 算法9.1 （EM算法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入: 观测变量数据$Y$，隐变量数据$Z$，联合概率分布$P(Y,Z|\\theta)$，条件概率分布(后验分布)$P(Z|Y,\\theta)$;  \n",
    "\n",
    "输出: 模型参数$\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）选择参数的初始值$\\theta^{(0)}$，开始迭代；  \n",
    "\n",
    "（2）E步: 记$\\theta^{(i)}$为第$i$步迭代参数$\\theta$的估计值，在第$i+1$次迭代的E步，计算  \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "Q(\\theta,\\theta^{(i)}) &=& E_{z}\\left[ \\log P(Y,Z|\\theta)|Y,\\theta^{(i)} \\right]  \\\\\n",
    "&=& \\sum_{Z}\\log P(Y,Z|\\theta) P(Z|Y,\\theta^{(i)}) \\tag{9.9}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）M步: 求使$Q(\\theta,\\theta^{(i)})$极大化的$\\theta$，确定$i+1$次迭代的参数估计值$\\theta^{(i+1)}$  \n",
    "\n",
    "$$\\theta^{(i+1)}=\\arg \\max _{\\theta} Q\\left(\\theta, \\theta^{(i)}\\right) \\tag{9.10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）重复第（2）和第（3）步，直到收敛。一般是对较小的正数$\\varepsilon_{1}, \\varepsilon_{2}$，若满足下面条件则停止迭代:  \n",
    "\n",
    "$$\n",
    "\\left\\|\\theta^{(i+1)}-\\theta^{(i)}\\right\\|<\\varepsilon_{1}  \\quad \n",
    "\\text{or}\\quad  \\left\\|Q\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right)-Q\\left(\\theta^{(i)}, \\theta^{(i)}\\right)\\right\\|<\\varepsilon_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义9.1 （Q函数）  \n",
    "完全数据的对数似然函数$\\log P(Y,Z|\\theta)$关于在给定观测数据$Y$和当前参数$\\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y, \\theta^{(i)})$的期望称为$Q$函数:  \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\color{blue}{Q\\left(\\theta, \\theta^{(i)}\\right)} &=& E_{Z}\\left[\\log P(Y, Z \\mid \\theta) \\mid Y, \\theta^{(i)}\\right]  \\\\\n",
    "&=& \\color{blue}{\\sum_{Z}\\log P(Y,Z|\\theta)~P(Z|Y,\\theta^{(i)})} \\tag{9.11}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 EM算法的导出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观测数据$Y$的对数似然函数为:  \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "L(\\theta) &= \\log P(Y|\\theta) = \\log \\sum_{Z} P(Y,Z|\\theta) \\\\ \n",
    "&= \\color{red}{\\log} \\left( \\color{red}{\\sum_{Z}} P(Y|Z,\\theta)P(Z|\\theta) \\right) \\tag{9.12}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>想极大化上式，主要困难点一是含有未观测数据$Z$；二是$\\log \\sum$不易求偏导。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事实上，EM算法是通过迭代逐步近似极大化$L(\\theta)$。假设第$i$次迭代后的$\\theta$估计值是$\\theta^{(i)}$。我们希望新的估计值$\\theta$能使$L(\\theta)$增加，即$L(\\theta) > L(\\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差:  \n",
    "\n",
    "$$\n",
    "L(\\theta)-L\\left(\\theta^{(i)}\\right)=\\log \\left(\\sum_{Z} P(Y \\mid Z, \\theta) P(Z \\mid \\theta)\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用Jensen不等式，得到下界: \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "L(\\theta)-L\\left(\\theta^{(i)}\\right) &=& \\log \\left(\\sum_{Z} P(Y \\mid Z, \\theta) P(Z \\mid \\theta)\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\\n",
    "&=& \\log \\left(\\sum_{Z} \\color{red}{P(Z \\mid Y, \\theta^{(i)})} \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{\\color{red}{P(Z \\mid Y, \\theta^{(i)})}} \\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\ \n",
    "&\\geq & \\sum_{Z} P(Z \\mid Y, \\theta^{(i)}) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P(Z \\mid Y, \\theta^{(i)})} - \\sum_{Z} P(Z \\mid Y, \\theta^{(i)})\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\\n",
    "&=& \\sum_{Z} P(Z \\mid Y, \\theta^{(i)}) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P(Z \\mid Y, \\theta^{(i)})P\\left(Y \\mid \\theta^{(i)}\\right)}\n",
    "\\end{eqnarray}  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>通过别的概率分布构造行吗？比如$P(Z|\\theta^{(i)})$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令  \n",
    "\n",
    "$$\n",
    "B\\left(\\theta, \\theta^{(i)}\\right) \\hat{=} L\\left(\\theta^{(i)}\\right)+\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)} \\tag{9.13}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则有  \n",
    "\n",
    "$$\n",
    "L(\\theta) \\geq B(\\theta, \\theta^{(i)}) \\tag{9.14}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，$B(\\theta, \\theta^{(i)})$是$L(\\theta)$的下界。且由（9.13）可知  \n",
    "\n",
    "$$\n",
    "L(\\theta^{(i)}) = B(\\theta^{(i)}, \\theta^{(i)}) \\tag{9.15}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，任何可以使$B(\\theta, \\theta^{(i)})$增大的$\\theta$，也可以使$L(\\theta)$增大。为了使$L(\\theta)$有尽可能大的增长，选择$\\theta^{(i+1)}$使$B(\\theta, \\theta^{(i)})$达到极大，即  \n",
    "\n",
    "$$\\theta^{(i+1)}=\\arg \\max _{\\theta} B\\left(\\theta, \\theta^{(i)}\\right) \\tag{9.16}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\theta ^ { ( i + 1 ) } &=& \\arg \\max _ { \\theta } \\left( L \\left( \\theta ^ { ( i ) } \\right) + \\sum _ { Z } P \\left( Z \\mid Y , \\theta ^ { ( i ) } \\right) \\log \\frac { P ( Y \\mid Z , \\theta ) P ( Z \\mid \\theta ) } { P \\left( Z \\mid Y , \\theta ^ { ( i ) } \\right) P \\left( Y \\mid \\theta ^ { ( i ) } \\right) } \\right)  \\\\\n",
    "&=& \\arg \\max _{\\theta}\\left(\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log (P(Y \\mid Z, \\theta) P(Z \\mid \\theta))\\right) \\\\\n",
    "&=& \\arg \\max _{\\theta}\\left(\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log P(Y, Z \\mid \\theta)\\right) \\\\\n",
    "&=& \\arg \\max_{\\theta}Q\\left(\\theta,\\theta^{(i)}\\right) \\tag{9.17}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>EM算法通过不断求解下界的极大化逼近求解对数似然函数极大化的算法。</font>这一点与改进的迭代尺度法求最大熵模型类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='9_EM算法的解释.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>从图中可以推断出EM算法不能保证找到全局最优值。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 EM算法的收敛性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定理9.1\n",
    "设$P(Y|\\theta)$为观测数据的似然函数，$\\theta^{(i)}(i=1,2,\\cdots,)$为EM算法得到的参数估序列，$P(Y|\\theta)^{(i)}(i=1,2,\\cdots,)$为对应的似然函数序列，则$P(Y|\\theta)^{(i)})是单调递增的，即  \n",
    "\n",
    "$$\n",
    "P\\left(Y \\mid \\theta^{(i+1)}\\right) \\geqslant P\\left(Y \\mid \\theta^{(i)}\\right) \\tag{9.18}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P\\left(Y | \\theta \\right) = \\frac{P\\left(Y,Z | \\theta \\right)}{P\\left(Z |Y \\theta \\right)}\n",
    "$$  \n",
    "\n",
    "取对数  \n",
    "\n",
    "$$\n",
    "\\log P\\left(Y | \\theta \\right) = \\log P\\left(Y,Z | \\theta \\right) - \\log P\\left(Z |Y \\theta \\right)\n",
    "$$\n",
    "\n",
    "等式两边同时对分布$P(Z|Y,\\theta^{(i)})$求期望  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "left &= \\sum_{Z}\\log P\\left(Y | \\theta \\right) P(Z|Y,\\theta^{(i)}) \\\\\n",
    "&= \\log P\\left(Y | \\theta \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "right &= \\sum_{Z}\\log P\\left(Y,Z | \\theta \\right)P(Z|Y,\\theta^{(i)})  - \\underset{令为H(\\theta, \\theta^{(i)})}{\\sum_{Z}\\log P\\left(Z |Y \\theta \\right)P(Z|Y,\\theta^{(i)})} \\\\\n",
    "&= Q(\\theta, \\theta^{(i)}) - H(\\theta, \\theta^{(i)})\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，有\n",
    "\n",
    "$$\n",
    "\\log P\\left(Y | \\theta \\right) = Q(\\theta, \\theta^{(i)}) - H(\\theta, \\theta^{(i)}) \\tag{9.20}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对（9.20）分别取$\\theta$为$\\theta^{(i)}$和$\\theta^{(i+1)}$并相减，有  \n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\log P\\left(Y \\mid \\theta^{(i+1)}\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\\n",
    "= \\left[Q\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right) - Q\\left(\\theta^{(i)}, \\theta^{(i)}\\right)\\right] -  \\left[H\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right)-H\\left(\\theta^{(i)}, \\theta^{(i)}\\right)\\right] \\tag{9.21}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了证明定理，只需证明（9.21）右端是非负的。对应上式第一项，因为$\\theta^{(i+1)}$使$Q(\\theta, \\theta^{(i)})$达到极大，因此  \n",
    "\n",
    "$$\n",
    "Q\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right) - Q\\left(\\theta^{(i)}, \\theta^{(i)}\\right) \\geq 0 \\tag{9.22}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9.21)式第二项  \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "H\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right)-H\\left(\\theta^{(i)}, \\theta^{(i)}\\right) &=& \\sum_{Z}\\left(\\log \\frac{P\\left(Z \\mid Y, \\theta^{(i+1)}\\right)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right)}\\right) P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\\\\n",
    "&\\leqslant& \\log \\left(\\sum_{Z} \\frac{P\\left(Z \\mid Y, \\theta^{(i+1)}\\right)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right)} P\\left(Z \\mid Y, \\theta^{(i)}\\right)\\right) \\\\\n",
    "&=& \\log \\left(\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i+1)}\\right)\\right)=0 \\tag{9.23}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由（9.22）和（9.23）可知（9.21）式右端是非负的，证毕。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定理9.2\n",
    "\n",
    "设$L(\\theta)=\\log P(Y|\\theta)$为观测数据的对数似然函数，$\\theta^{(i)}(i=1,2,\\cdots,)$为EM算法得到的参数估序列，$L(\\theta^{(i)})(i=1,2,\\cdots,)$为对应的对数似然函数序列。  \n",
    "\n",
    "（1）如果$P(Y|\\theta)$有上界，则$L(\\theta^{(i)})=\\log P(Y|\\theta^{(i)})$收敛到某一值$L^{*}$  （<font color=blue>单调有界必收敛</font>）\n",
    "\n",
    "（2）在函数$Q\\left(\\theta, \\theta^{\\prime}\\right)$与$L(\\theta)$满足一定条件下，由EM算法得到的参数估计序列$\\theta^{(i)}$的收敛值$\\theta^{(*)}$是$L(\\theta)$的稳定点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EM算法的收敛性包含关于对数似然函数序列$L(\\theta^{(i)})$的收敛性和关于参数估计序列$\\theta^{(*)}$的收敛性两层意思，前者不蕴含后者。\n",
    "\n",
    "\n",
    "2. <font color=blue>定理只保证参数估计序列收敛到对数似然函数序列的稳定点，不能保证收敛到极大值点。</font>在实际应用中，常选取不同的初始值进行迭代，然后对估计值进行比较选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
