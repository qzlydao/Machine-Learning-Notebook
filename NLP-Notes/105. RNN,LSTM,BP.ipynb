{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Outline\n",
    "\n",
    "1. RNN\n",
    "\n",
    "2. BP for RNN\n",
    "\n",
    "3. LSTM\n",
    "\n",
    "4. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Recall: Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/105. Feedforward Neural Network.jpg' style='zoom:40%'/>\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z &= \\sum_{i=1}^{n}w_{i}x_{i}+b \\\\\n",
    "a &= g(z)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Recall: Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A language model estimates probabilities of sequence of words:\n",
    "\n",
    "- For the sequence $\\color{MediumOrchid}{w_{1}, w_{2}, \\cdots, w_{n}}$，using the chain rule, we have:\n",
    "\n",
    "$$\n",
    "\\color{MediumOrchid}{P\\left(w_{1}, \\ldots, w_{n}\\right)=P\\left(w_{n} \\mid w_{1}, \\ldots, w_{n-1}\\right) P\\left(w_{n-1} \\mid w_{1}, \\ldots, w_{n-2}\\right) \\ldots P\\left(w_{2} \\mid w_{1}\\right) P\\left(w_{1}\\right)}\n",
    "$$\n",
    "\n",
    "- N-Gram Approximation: $\\color{MediumOrchid}{P\\left(w_{1}, \\ldots, w_{n}\\right)=\\prod_{i=1}^{n} P\\left(w_{i} \\mid w_{i-N+1}, \\ldots, w_{i-1}\\right)}$\n",
    "\n",
    "- Applications:\n",
    "    - Machine Translation: $\\color{MediumOrchid}{P(\\text { the cat is small })>P(\\text { small is the cat })}$\n",
    "    \n",
    "    - Grammar Checking: $\\color{MediumOrchid}{P(\\text { He graduated from SJTU. })>P(\\text { He graduated on SJTU.) }}$\n",
    "    \n",
    "    \n",
    "Context is import in modelling context,But:\n",
    "\n",
    "- N-Gram models use only limited context;\n",
    "\n",
    "- They failed to handling long(>N) dependencies which is common seen in NL.\n",
    "\n",
    "RNNs Could address the above issues: \n",
    "\n",
    "- <font color=red>It includes the previous hidden layer as the input;</font>\n",
    "\n",
    "- <font color=red>It could model dependencies of arbitrary length.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Why RNN？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**通用近似定理(Universal Approximation Theorem)**\n",
    "\n",
    "一个包含足够多隐含层神经元的多层前馈网络，能以任意精度逼近任意预定的连续函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simple RNN Architecture\n",
    "\n",
    "<img src='attachment/105. Simple RNN Architecture.png' style='zoom:40%'/>\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "h^{(t)} &= \\sigma\\left(Wx^{(t)} + Uh^{(t-1)} \\right) \\\\\n",
    "y^{(t)} &= Softmax  \\left(Vh^{(t)} \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语言模型的评价指标：\n",
    "\n",
    "1. 困惑度（Perplexity，ppl）\n",
    "\n",
    "2. 词错误率（Word Error Rate, WER）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Unfolding RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Full RNN use all previous time steps: \n",
    "\n",
    "<img src='attachment/105. Full RNN.png' style='zoom:40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Backprop of $V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设Loss function: \n",
    "\n",
    "$$L=\\sum_{t=1}^{T} \\ell\\left(y^{(t)}, \\hat{y}^{(t)}\\right)$$\n",
    "\n",
    "令 $\\color{MediumOrchid}{z = Vh}$，则损失函数对 $\\color{MediumOrchid}{V}$的偏导数可表示为:\n",
    "\n",
    "$$\n",
    "\\color{MediumOrchid}{\\frac{\\partial \\ell^{(t)}}{\\partial V}=\\frac{\\partial \\ell^{(t)}}{\\partial y^{(t)}} \\cdot \\frac{\\partial y^{(t)}}{\\partial z^{(t)}} \\cdot \\frac{\\partial z^{(t)}}{\\partial V}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Backprop through Time（BPTT）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\ell^{(t)}}{\\partial W} &= \\frac{\\partial \\ell^{(t)}}{\\partial y^{(t)}} \\cdot \\frac{\\partial y^{(t)}}{\\partial h^{(t)}} \\cdot \\frac{\\partial h^{(t)}}{\\partial W}\\\\\n",
    "&+ \\frac{\\partial \\ell^{(t)}}{\\partial y^{(t)}} \\cdot \\frac{\\partial y^{(t)}}{\\partial h^{(t)}} \\cdot \\frac{\\partial h^{(t)}}{\\partial h^{(t-1)}} \\cdot \\frac{\\partial h^{(t-1)}}{\\partial W} \\\\\n",
    "&+ \\frac{\\partial \\ell^{(t)}}{\\partial y^{(t)}} \\cdot \\frac{\\partial y^{(t)}}{\\partial h^{(t)}} \\cdot \\frac{\\partial h^{(t)}}{\\partial h^{(t-1)}} \\cdot \\frac{\\partial h^{(t-1)}}{\\partial h^{(t-2)}} \\cdot \\frac{\\partial h^{(t-2)}}{\\partial W} \\\\\n",
    "&+  \\cdots\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sum: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell^{(t)}}{\\partial W} = \\sum_{k=0}^{t} \\frac{\\partial \\ell^{(t)}}{\\partial y^{(t)}} \\cdot \\frac{\\partial y^{(t)}}{\\partial h^{(t)}} \\left(\\prod_{j=k+1}^{t}\\frac{ \\partial h^{(j)}}{\\partial h^{(j-1)}} \\right) \\cdot \\frac{\\partial h^{(k)}}{\\partial W}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Real-Time Recurrent Learning（RTRL）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\ell^{(t)}}{\\partial U} = \\frac{\\partial \\ell^{(t)}}{\\partial h^{(t)}} \\cdot \\frac{\\partial h^{(t)}}{\\partial U}\n",
    "$$\n",
    "\n",
    "令 \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "h^{(t)} &= f\\left(z^{(t)}\\right) \\\\\n",
    "&= f\\left(Uh^{(t-1)} + Wx^{(t)}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "则\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial h^{(t)}}{\\partial U} &= \\frac{\\partial h^{(t)}}{\\partial z^{(t)}} \\left(\\frac{\\partial z^{(t)}}{\\partial U} + U\\frac{\\partial h^{(t-1)}}{\\partial U} \\right) \\\\\n",
    "&= f^{\\prime} \\left( z^{(t)} \\right) \\odot \\left(h^{(t-1)} + U\\frac{\\partial h^{(t-1)}}{\\partial U} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Vanishing Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\ell^{(t)}}{\\partial W} = \\sum_{k=0}^{t} \\frac{\\partial \\ell^{(t)}}{\\partial y^{(t)}} \\cdot \\frac{\\partial y^{(t)}}{\\partial h^{(t)}} \\left( \\color{MediumOrchid}{\\prod_{j=k+1}^{t}\\frac{ \\partial h^{(j)}}{\\partial h^{(j-1)}}} \\right) \\cdot \\frac{\\partial h^{(k)}}{\\partial W}\n",
    "$$\n",
    "\n",
    "<img src='105. Vanishing Gradients.jpg' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 原始LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/105. LSTM.png' style='zoom:70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 遗忘门\n",
    "\n",
    "$$\n",
    "f_{t} = \\sigma\\left( W_{f} \\cdot \\left[h_{t-1}, x_{t}\\right] + b_{f} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入门\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "i_{t} &= \\sigma \\left(W_{i} \\cdot \\left[h_{t-1}, x_{t}\\right] + b_{i}\\right) \\\\\n",
    "\\tilde{C}_{t} &= \\tanh \\left(W_{C} \\cdot \\left[h_{t-1}, x_{t}\\right] + b_{C}\\right) \\\\\n",
    "C_{t} &= f_{t} * C_{t-1} + i_{t} * \\tilde{C}_{t}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输出门\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "o_{t} &= \\sigma \\left(W_{o} \\cdot \\left[h_{t-1}, x_{t}\\right] + b_{o}\\right) \\\\\n",
    "h_{t} &= o_{t} * \\tanh \\left(C_{t}\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 变种1: adding peephold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='105. LSTM with peephold connection.jpg' style='zoom:50%'/> \n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "f_{t} &=\\sigma\\left(W_{f} \\cdot\\left[\\color{red}{{C}_{t-1}}, h_{t-1}, x_{t}\\right]+b_{f}\\right) \\\\ \n",
    "i_{t} &=\\sigma\\left(W_{i} \\cdot\\left[\\color{red}{{C}_{t-1}}, h_{t-1}, x_{t}\\right]+b_{i}\\right) \\\\ \n",
    "o_{t} &=\\sigma\\left(W_{o} \\cdot\\left[\\color{red}{{C}_{t}}, h_{t-1}, x_{t}\\right]+b_{o}\\right) \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 变种2：GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='105. GRU.jpg' style='zoom:50%'/> \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z_{t} &= \\sigma\\left(W_{z} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\\\\n",
    "r_{t} &= \\sigma\\left(W_{r} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\\\\n",
    "\\tilde{h}_{t} &= \\tanh \\left(W \\cdot\\left[r_{t} * h_{t-1}, x_{t}\\right]\\right) \\\\\n",
    "h_{t} &= \\left(1-z_{t}\\right) * h_{t-1}+z_{t} * \\tilde{h}_{t}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 RNNs for Classification\n",
    "\n",
    "<img src='attachment/105. RNNs for Classification.jpg' style='zoom:30%'/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 POS Tagging\n",
    "\n",
    "<img src='attachment/105. POS Tagging.jpg' style='zoom:30%'/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 NER\n",
    "\n",
    "<img src='attachment/105. NER.jpg' style='zoom:30%'/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Machine Translation-Encoder_Decoder Architecture\n",
    "\n",
    "<img src='attachment/105. Machine Translation-Encoder_Decoder Architecture.png' style='zoom:30%'/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
