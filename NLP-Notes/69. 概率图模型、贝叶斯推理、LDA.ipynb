{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Models**\n",
    "\n",
    "- Why Bayesian？\n",
    "\n",
    "\n",
    "- MLE、MAP、Bayesian Estimation  \n",
    "\n",
    "\n",
    "- Bayesian Inference\n",
    "\n",
    "    - Approximate Inference\n",
    "        - MCMC\n",
    "        - Variational Inference\n",
    "        \n",
    "\n",
    "- LDA Model\n",
    "\n",
    "\n",
    "- Inference of LDA\n",
    "    - Gibbs Sampling\n",
    "    - Collapsed Gibbs Sampling\n",
    "    - Variational Inference\n",
    "    - Stochastic Gradient MCMC\n",
    "    - Stochastic Variational Inference\n",
    "    - Distributed MCMC\n",
    "    \n",
    "    \n",
    "- Other Bayesian Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Why Bayesian?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LDA（Latent Dirichlet Allocation）is popular\n",
    "\n",
    "LDA vs. k-means:  \n",
    "> LDA给出是属于各个主体的概率分布；（软分类）  \n",
    "k-means是硬分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. <font color=red>Small Data Problem</font>  \n",
    "\n",
    "当数据量比较小时，模型容易Overfitting。集成模型可以解决Overfitting，而Bayesian Model可以看做是集成模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Incorporate Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 先验（Incorporate Prior）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MLE、MAP、Bayesian Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/69. MLE_MAP_Bayesian.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\int_{\\theta}P(y^{\\prime}\\mid x^{\\prime};\\theta) ~ \\color{red}{P(\\theta\\mid D)}~\\mathrm{d}\\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何计算后验$P(\\theta|D)$是问题的关键.若$\\theta \\in \\mathbf{R}^{d}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "P(\\theta \\mid D) & = & \\frac{P(D \\mid \\theta) P(\\theta)}{P(D)}  =  \\frac{P(D \\mid \\theta) p(\\theta)}{\\int_{\\theta} P(D, \\theta) d \\theta} \\\\ \n",
    "& = & \\int_{\\theta_{1}}\\int_{\\theta_{2}}\\cdots \\int_{\\theta_{d}}P(D,\\theta)~\\mathrm{d}\\theta_{1}~\\mathrm{d}\\theta_{1}~\\cdots \\mathrm{d}\\theta_{d}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若$~\\theta~$维度很高，问题是Intractable的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Approximate Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y} &= \\int_{\\theta}P(y^{\\prime}\\mid x^{\\prime};\\theta) ~ \\color{red}{P(\\theta\\mid D)}~\\mathrm{d}\\theta \\\\\n",
    "&= \\mathbb{E}_{P(\\theta|D)}\\left[ P(y^{\\prime}\\mid x^{\\prime};\\theta) \\right] \\\\\n",
    "& \\approx \\frac{1}{S}\\sum_{s=1}^{S}P(y^{\\prime}\\mid x^{\\prime};\\theta^{s}) \\\\\n",
    "\\theta^{s} & \\sim P(\\theta|D)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LDA（Latent Dirichlet Allocation）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/69. LDA模型.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA是生成模型，记Doc-Topic为$~\\theta$，Topic-word 为$~\\phi$，则文章的生成过程为\n",
    "\n",
    "若文章包含$~n~$个单词，主题分布为$(0.6, 0.2, 0.1, 0.1)$，则生成过程为:\n",
    "\n",
    "$$\n",
    "for \\quad i=1,2,\\cdots,n: \\\\\n",
    "\\quad Z_{i} \\sim \\text{Mult}(n,p) \\\\\n",
    "\\quad w_{i} \\sim \\text{Mult}(\\phi_{Z_{i}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/69. LDA生成文本过程.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "\\theta_{i}: \\text{Topic Distribution of Document} ~ i\\\\\n",
    "\\phi_{k}: \\text{Word Distribution Under Topic} ~ k \\\\\n",
    "Z_{ij}: \\text{topic of jth word in Document} ~ i \\\\\n",
    "w_{ij}: word/observation  \\\\\n",
    "\\alpha, \\beta : prior(known)\\\\\n",
    "\\end{array} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Model Parameter:}~ \\theta, \\phi$ \n",
    "\n",
    "$\\text{Hyperparameter:}~ \\alpha, \\beta$\n",
    "\n",
    "$\\text{latent parameter:}~z$\n",
    "\n",
    "$\\text{Observation:}~x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: 根据先验$~\\alpha$ 生成 $\\theta_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{}\n",
    "for \\quad i=1,2,\\cdots,N \\quad // ~ \\text{iterate each doc} \\\\\n",
    "\\quad \\quad \\theta_{i} \\longleftarrow \\alpha\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{i}= (\\theta_{i1}, \\theta_{i2}, \\cdots, \\theta_{iK})~$的特点:  \n",
    "1. $\\theta_{ij} \\geq 0$  \n",
    "\n",
    "\n",
    "2. $\\sum_{j=1}^{K}\\theta_{ij}=1$\n",
    "\n",
    "\n",
    "$\\theta_{i} \\sim \\text{Dir}(\\alpha)$ \n",
    "\n",
    "i.e; &nbsp; $k=4, \\alpha=(0.1, 0.1, 0.1, 0.1) \\quad \\theta_{i}=(0.5, 0.3, 0.1, 0.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: 根据$\\theta_{i}$确定第$~j~$个word的话题$Z_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Z_{ij} \\sim \\text{Mult}(\\theta_{i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: 根据超参数$\\beta$生成$\\phi_{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{}\n",
    "for \\quad k=1,2,\\cdots,K \\quad // ~ \\text{iterate each topic} \\\\\n",
    "\\quad \\quad \\phi_{k} \\longleftarrow \\beta\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi_{k}=(\\phi_{k1}, \\phi_{k2}, \\cdots, \\phi_{k|V|})$的特点：\n",
    "1. $\\phi_{kj} \\geq 0$ \n",
    "\n",
    "\n",
    "2. $\\sum_{j=1}^{|V|}\\phi_{kj}$=1\n",
    "\n",
    "$\\phi_{k} \\sim \\text{Dir}(\\beta) \\quad \\beta\\in \\mathbf{R}^{|V|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: 根据$Z_{ij}, \\phi$生成单词$w_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{ij} \\sim \\text{Mult}(\\phi_{Z_{ij}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Hyperparameter:}~ \\alpha, \\beta$ \n",
    "\n",
    "$\\text{Model Params:}~ \\theta,\\phi$\n",
    "\n",
    "$\\text{Hidden Vars:}~ Z$ \n",
    "\n",
    "$\\text{Observations:}~ w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Inference: $P(\\theta, \\phi, Z|\\alpha, \\beta, w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Gibbs Sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\theta \\sim P(\\theta|w, \\alpha, \\beta, \\phi, Z)$\n",
    "\n",
    "2. $\\phi \\sim P(\\phi|w, \\alpha, \\beta, \\theta, Z)$\n",
    "\n",
    "3. $Z \\sim P(Z|w, \\alpha, \\beta, \\theta, \\phi)$\n",
    "\n",
    "具体地，\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "for \\quad i=1,2,\\cdots,N \\\\\n",
    "\\quad \\quad \\theta_{i} \\sim P(\\theta_{i}|w, \\alpha, \\beta, \\phi, Z, \\theta_{-i}) \\\\\n",
    "\\quad \\\\\n",
    "for \\quad k=1,2,\\cdots,K \\\\\n",
    "\\quad \\quad  \\phi_{k} \\sim P(\\phi_{k}|w, \\alpha, \\beta, \\theta, Z, \\phi_{-k}) \\\\\n",
    "\\quad \\\\\n",
    "for \\quad i=1,2,\\cdots,N \\\\\n",
    "\\quad for \\quad j=1,2,\\cdots,N_{i} \\\\\n",
    "\\quad \\quad \\quad Z_{ij} \\sim P(Z_{ij}|w, \\alpha, \\beta, \\theta, \\phi, Z_{-ij})\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Markov Blanket（马尔科夫毯）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/69. Markov Blanket.jpg' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于上面的贝叶斯网络，有  \n",
    "\n",
    "$$\n",
    "P(a|b,c,d,e,f,h,j,k,l,m) = P(a|b,c,d,e,f)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 $\\theta_{i}$的后验分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于$~\\theta_{i}$，有\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{i} & \\sim P(\\theta_{i}|w, \\alpha, \\beta, \\phi, Z, \\theta_{-i}) \\\\\n",
    "&= P(\\theta_{i}|\\alpha, Z) \\quad(markov ~ blanket) \\\\\n",
    "&= P(\\theta_{i}|\\alpha, \\left\\{Z_{ij}\\right\\}_{j=1}^{N_{i}}) \\\\\n",
    "&= \\frac{P\\left(\\theta_{i},\\alpha, \\left\\{Z_{ij}\\right\\}_{j=1}^{N_{i}}\\right)}{P\\left(\\alpha, \\left\\{Z_{ij}\\right\\}_{j=1}^{N_{i}}\\right)} \\\\\n",
    "&= \\frac{P(\\alpha)\\cdot P(\\theta_{i}|\\alpha)\\cdot P\\left(\\left\\{Z_{ij}\\right\\}|\\theta_{i}\\right)}{P\\left(\\alpha, \\left\\{Z_{ij}\\right\\}_{j=1}^{N_{i}}\\right)}\\\\\n",
    "& \\propto \\underset{prior}{P(\\theta_{i}|\\alpha)}\\cdot \\underset{likelihood}{P\\left(\\left\\{Z_{ij}\\right\\}|\\theta_{i}\\right)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "&\\quad \\underset{Dirichlet}{P(\\theta_{i}|\\alpha)}\\cdot \\underset{Mult}{P\\left(\\left\\{Z_{ij}\\right\\}|\\theta_{i}\\right)} \\\\\n",
    "&= \\frac{1}{B(\\alpha)}\\prod_{k=1}^{K}\\theta_{ik}^{\\alpha_{k}~-1} \\cdot \\prod_{j=1}^{N_{i}}\\prod_{k=1}^{K}\\theta_{ik}^{I(Z_{ij}~=k)} \\\\\n",
    "&= \\frac{1}{B(\\alpha)} \\prod_{k=1}^{K} \\theta_{ik}^{\\sum_{j=1}^{N_{~i}}~I(Z_{ij}~=k)+\\alpha_{k}-1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此有，\n",
    "\n",
    "$$\n",
    "P(\\theta_{i} | \\alpha) \\sim \\text{Dir}\\left(\\alpha+\\sum_{j=1}^{N_{i}}I(Z_{ij}=k)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 共轭分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先验: $P(\\theta_{i}|\\alpha) \\sim \\text{Dir}(\\alpha)$ \n",
    "\n",
    "likehood: $P(\\left\\{ Z_{ij} \\right\\}|\\theta_{i}) \\sim \\text{Mult}(\\theta_{i})$ \n",
    "\n",
    "后验: $P(\\theta_{i} | \\alpha) \\sim \\text{Dir}\\left(\\alpha+\\sum_{j=1}^{N_{i}}I(Z_{ij}=k)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $Z_{ij}$的后验分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='attachment/69. LDA生成文本过程.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "&\\quad P(Z_{ij} = k|w, \\alpha, \\beta, \\phi, \\theta, Z_{-ij}) \\\\\n",
    "\\quad \\\\\n",
    "&= P(Z_{ij} = k|w_{ij}, \\phi_{k}, \\theta_{i}) \\\\\n",
    "\\quad \\\\\n",
    "&= \\frac{P(Z_{ij} = k, w_{ij}, \\phi_{k}, \\theta_{i})}{P(w_{ij}, \\phi_{k}, \\theta_{i})} \\\\\n",
    "\\quad \\\\\n",
    "&= \\frac{P(\\theta_{i})P(Z_{ij}=k|\\theta_{i})P(w_{ij}|Z_{ij}=k,\\phi_{k})}{P(w_{ij}, \\phi_{k}, \\theta_{i})} \\\\\n",
    "\\quad \\\\\n",
    "&\\propto P(Z_{ij}=k|\\theta_{i})\\cdot P(w_{ij}|\\phi_{k}) \\\\\n",
    "\\quad \\\\\n",
    "&= \\theta_{ik} \\cdot \\phi_{k,w_{ij}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，\n",
    "\n",
    "$$\n",
    "P(Z_{ij} = k|w, \\alpha, \\beta, \\phi, \\theta, Z_{-ij}) = \\frac{\\theta_{ik} \\cdot \\phi_{k,w_{ij}}}{\\sum_{k}\\theta_{ik} \\cdot \\phi_{k,w_{ij}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 $\\phi_{k}$的后验分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\phi_{k} &\\sim P(\\phi_{k}|w, \\alpha, \\beta, \\theta, Z, \\phi_{-k}) \\\\\n",
    "\\quad \\\\\n",
    "& = P(\\phi_{k}|w_{ij}, \\beta,  Z_{ij}) \\\\\n",
    "\\quad \\\\\n",
    "& = \\frac{P(\\phi_{k}, w_{ij}, \\beta,  Z_{ij})}{P(w_{ij}, \\beta,  Z_{ij})} \\\\\n",
    "\\quad \\\\\n",
    "& = \\frac{P(\\beta)\\cdot P(\\phi_{k}|\\beta)\\cdot P(w_{ij}|Z_{ij}, \\phi_{k})}{P(w_{ij}, \\beta,  Z_{ij})} \\\\\n",
    "\\quad \\\\\n",
    "& \\propto  \\underset{prior}{P(\\phi_{k}|\\beta)} \\cdot \\underset{likelihood}{P(w_{ij}|\\phi_{k})} \\\\\n",
    "\\quad \\\\\n",
    "& = \\frac{1}{B(\\beta)}\\prod_{v=1}^{|V|}\\phi_{k,v}^{\\beta_{v}-1} \\cdot \\prod_{i=1}^{N}\\prod_{j=1}^{N_{i}}\\prod_{v=1}^{|V|}\\phi_{k,v}^{I(w_{ij}~=v)} \\\\\n",
    "\\quad \\\\\n",
    "& = \\frac{1}{B(\\beta)}\\prod_{v=1}^{|V|}\\phi_{k,v}^{\\sum_{i=1}^{N}\\sum_{j=1}^{N_{~i}}~I(w_{ij}~=v)+\\beta_{v}-1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此有，\n",
    "\n",
    "$$\n",
    "P(\\phi_{k}|w,\\alpha,\\theta, Z, \\phi_{-k}) = \\text{Dir}\\left(\\beta + \\sum_{i=1}^{N} \\sum_{j=1}^{N_{i}}I(w_{ij}=v)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Gibbs Sampling Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text{for} \\quad i=1,2,\\cdots,N \\\\\n",
    "\\quad \\quad \\theta_{i} \\sim P(\\theta_{i}|w, \\alpha, \\beta, \\phi, Z, \\theta_{-i}) \\\\\n",
    "\\quad \\\\\n",
    "\\text{for} \\quad k=1,2,\\cdots,K \\\\\n",
    "\\quad \\quad  \\phi_{k} \\sim P(\\phi_{k}|w, \\alpha, \\beta, \\theta, Z, \\phi_{-k}) \\\\\n",
    "\\quad \\\\\n",
    "\\text{for} \\quad i=1,2,\\cdots,N \\\\\n",
    "\\quad \\text{for} \\quad j=1,2,\\cdots,N_{i} \\\\\n",
    "\\quad \\quad \\quad Z_{ij} \\sim P(Z_{ij}|w, \\alpha, \\beta, \\theta, \\phi, Z_{-ij})\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们有两篇文档: \n",
    "\n",
    "<img src='69. Gibbs Sampling.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: 初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设一共有3个主题，共计4个单词，随机初始化$\\left\\{ Z_{ij} \\right\\}$，初始化为\n",
    "\n",
    "$K=3,~ \\alpha=(0.1, 0.1, 0.1),~ \\beta=(0.01, 0.01, 0.01, 0.01)$\n",
    "\n",
    "$Z_{11}=1,~ Z_{12}=2, ~Z_{12}=2, ~Z_{14}=3$  \n",
    "$Z_{21}=3,~ Z_{22}=1, ~Z_{23}=1, ~Z_{24}=2$\n",
    "\n",
    "词库: (我们，今天，上课，天气)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: 采样$~\\theta_{i}~(\\theta_{1}, \\theta_{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{i} \\sim \\text{Dir}\\left(\\alpha + \\sum_{j=1}^{N_{i}}I(Z_{ij}=k)\\right)$\n",
    "\n",
    "$\\theta_{i} \\sim \\text{Dir}\\left(\\alpha_{1} + n_{1}, \\alpha_{2} + n_{2}, \\alpha_{3} + n_{3})\\right)\\quad n_{i}:$ # of words belong to topic k.\n",
    "\n",
    "$\\therefore \\theta_{i} \\sim \\text{Dir}(0.1+1, 0.1+2, 0.1+1)$\n",
    "\n",
    "$\\therefore \\theta_{i} \\sim \\text{Dir}(1.1, 2.1, 1.1)$，采样得到 \n",
    "\n",
    "$\\theta_{1}=(0.2, 0.7, 0.1)$\n",
    "\n",
    "同理，可以采样得到\n",
    "\n",
    "$\\theta_{2}=(0.7, 0.25, 0.05)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3: 采样$~\\phi_{k}~(\\phi_{1}, \\phi_{2}, \\phi_{3})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi_{k} \\sim \\text{Dir}\\left( \\beta + \\sum_{i=1}^{N}\\sum_{j=1}^{N_{i}}I(w_{ij}=v)\\right)$\n",
    "\n",
    "$\\phi_{k} \\sim \\text{Dir}\\left( \\beta_{1} + m_{1},~ \\beta_{2} + m_{2},~ \\beta_{3} + m_{3},~ \\beta_{4} + m_{4}\\right) \\quad m_{i}:$ 词库里的第$~i~$个单词有多少次属于Topic $k$. \n",
    "\n",
    "$\\phi_{1} \\sim \\text{Dir}\\left( 0.01+2,~ 0.01+0,~ 0.01+0,~ 0.01+1 \\right)$，采样后得到$~\\phi_{1}$\n",
    "\n",
    "$\\phi_{1} = (0.8,~ 0.05,~ 0.05,~ 0.1)$\n",
    "\n",
    "$\\phi_{2} \\sim \\text{Dir}\\left( 0.01+0,~ 0.01+2,~ 0.01+1,~ 0.01+0 \\right)$，采样后得到$~\\phi_{2}$\n",
    "\n",
    "$\\phi_{2} = (0.05,~ 0.75,~ 0.15,~ 0.05)$\n",
    "\n",
    "$\\phi_{3} \\sim \\text{Dir}\\left( 0.01+1,~ 0.01+1,~ 0.01+0,~ 0.01+0 \\right)$，采样后得到$~\\phi_{3}$\n",
    "\n",
    "$\\phi_{3} = (0.45,~ 0.35,~ 0.15,~ 0.05)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step4: 采样$~Z_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(Z_{ij}=k|\\alpha, \\beta, w, \\theta, \\phi) \\propto \\theta_{ik}\\cdot \\phi_{k,w_{ij}}\n",
    "$$\n",
    "\n",
    "对于 $Z_{11}(我们)$\n",
    "\n",
    "$P(Z_{11}=1|-) \\propto \\theta_{11}\\cdot \\phi_{1,我们} \\quad = 0.2*0.8=0.16$\n",
    "\n",
    "$P(Z_{11}=2|-) \\propto \\theta_{12}\\cdot \\phi_{2,我们} \\quad = 0.7*0.05=0.035$\n",
    "\n",
    "$P(Z_{11}=3|-) \\propto \\theta_{13}\\cdot \\phi_{3,我们} \\quad = 0.1*0.45=0.045$\n",
    "\n",
    "$\\therefore \\quad P(Z_{11}=1|-)=\\frac{0.16}{0.16+0.035+0.045} \\quad P(Z_{11}=2|-)=\\frac{0.035}{0.16+0.035+0.045}\\quad P(Z_{11}=3|-)=\\frac{0.045}{0.16+0.035+0.045}$\n",
    "\n",
    "$\\therefore \\quad Z_{11} \\sim \\text{Mult}(\\frac{0.16}{0.24},~ \\frac{0.035}{0.24},~ \\frac{0.045}{0.24})$ 采样得到新的$Z_{11}$\n",
    "\n",
    "同理，采样得到$Z_{12}, ~Z_{13}, ~Z_{14}, ~Z_{21}, ~Z_{22}, ~Z_{23}, ~Z_{24}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 MCMC的两个阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC的两个阶段: \n",
    "\n",
    "1. Burn-in Period\n",
    "\n",
    "2. Collecting Samples\n",
    "\n",
    "6.6 节中介绍了一个迭代的采样过程，通过一次 Iteration，采样得到  \n",
    "\n",
    "$\\theta^{(i)}, ~ \\phi^{(i)}, ~Z^{(i)}$\n",
    "\n",
    "比如进行2000次Iteration，可能前1000次处于Burn-in阶段，而后进入Collting阶段，如何估计Burn-in的迭代次数，可以通过Perplexity曲线进行判断。\n",
    "\n",
    "<img src='attachment/69. Perplexity.png' style='zoom:50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{Final} &= \\frac{1}{1000}\\left(\\theta^{(1001)}+\\cdots+\\theta^{(2000)}\\right) \\\\\n",
    "\\phi_{Final} &= \\frac{1}{1000}\\left(\\phi^{(1001)}+\\cdots+\\phi^{(2000)}\\right) \\\\\n",
    "Z_{Final} &= \\frac{1}{1000}\\left(Z^{(1001)}+\\cdots+Z^{(2000)}\\right) \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity = $2^{-x}$，$x:$ average log likelihood.对于LDA，likelihood:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\quad P(w_{ij}|\\theta_{i}, \\phi) \\\\\n",
    "&= \\sum_{k}P(Z_{ij}=k|\\theta_{i})\\cdot P(w_{ij}|Z_{ij}=k,\\phi) \\\\\n",
    "&= \\sum_{k}P(Z_{ij}=k|\\theta_{i})\\cdot P(w_{ij}|\\phi_{k}) \n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
